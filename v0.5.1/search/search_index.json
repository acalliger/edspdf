{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview EDS-PDF provides modular framework to extract text from PDF documents. You can use it out-of-the-box, or extend it to fit your use-case. Getting started Installation Install the library with pip: $ pip install edspdf ---> 100% color:green Installation successful Extracting text Let's build a simple PDF extractor that uses a rule-based classifier, using the following configuration: config.cfg [reader] @ readers = \"pdf-reader.v1\" [reader.extractor] @ extractors = \"pdfminer.v1\" [reader.classifier] @ classifiers = \"mask.v1\" x0 = 0.2 x1 = 0.9 y0 = 0.3 y1 = 0.6 threshold = 0.1 [reader.aggregator] @ aggregators = \"simple.v1\" The PDF reader can be instantiated and applied (for instance with this PDF ): import edspdf from pathlib import Path reader = edspdf . load ( \"config.cfg\" ) # (1) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n... The reader object is loaded from the configuration directly. See the rule-based recipe for a step-by-step explanation of what is happening. Acknowledgement We would like to thank Assistance Publique \u2013 H\u00f4pitaux de Paris and AP-HP Foundation for funding this project.","title":"Overview"},{"location":"#overview","text":"EDS-PDF provides modular framework to extract text from PDF documents. You can use it out-of-the-box, or extend it to fit your use-case.","title":"Overview"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#installation","text":"Install the library with pip: $ pip install edspdf ---> 100% color:green Installation successful","title":"Installation"},{"location":"#extracting-text","text":"Let's build a simple PDF extractor that uses a rule-based classifier, using the following configuration: config.cfg [reader] @ readers = \"pdf-reader.v1\" [reader.extractor] @ extractors = \"pdfminer.v1\" [reader.classifier] @ classifiers = \"mask.v1\" x0 = 0.2 x1 = 0.9 y0 = 0.3 y1 = 0.6 threshold = 0.1 [reader.aggregator] @ aggregators = \"simple.v1\" The PDF reader can be instantiated and applied (for instance with this PDF ): import edspdf from pathlib import Path reader = edspdf . load ( \"config.cfg\" ) # (1) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n... The reader object is loaded from the configuration directly. See the rule-based recipe for a step-by-step explanation of what is happening.","title":"Extracting text"},{"location":"#acknowledgement","text":"We would like to thank Assistance Publique \u2013 H\u00f4pitaux de Paris and AP-HP Foundation for funding this project.","title":"Acknowledgement"},{"location":"alternatives/","text":"Alternatives & Comparison EDS-PDF was developed to propose a more modular and extendable approach to PDF extraction than PDFBox , the legacy implementation at APHP's clinical data warehouse.","title":"Alternatives & Comparison"},{"location":"alternatives/#alternatives-comparison","text":"EDS-PDF was developed to propose a more modular and extendable approach to PDF extraction than PDFBox , the legacy implementation at APHP's clinical data warehouse.","title":"Alternatives &amp; Comparison"},{"location":"changelog/","text":"Changelog v0.5.1 - 2022-07-26 Changed Drop the pdf2image dependency, replacing it with pypdfium2 (easier installation) v0.5.0 - 2022-07-25 Changed Major refactoring of the library. Moved from concepts ( aggregation ) to plural names ( aggregators ). v0.4.3 - 2022-07-20 Fixed Multi page boxes alignment v0.4.2 - 2022-07-06 Added package-resource.v1 in the misc registry v0.4.1 - 2022-06-14 Fixed Remove importlib.metadata dependency, which led to issues with Python 3.7 v0.4.0 - 2022-06-14 Added Python 3.7 support, by relaxing dependency constraints Support for package-resource pipeline for sklearn-pipeline.v1 v0.3.2 - 2022-06-03 Added compare_results in visualisation v0.3.1 - 2022-06-02 Fixed Rescale transform now keeps origin on top-left corner v0.3.0 - 2022-06-01 Added Styles management within the extractor styled.v1 aggregator, to handle styles rescale.v1 transform, to go back to the original height and width Changed Styles and text extraction is handled by the extractor directly The PDFMiner line object is not carried around any more Removed Outdated params entry in the EDS-PDF registry. v0.2.2 - 2022-05-12 Changed Fixed merge_lines bug when lines were empty Modified the demo consequently v0.2.1 - 2022-05-09 Changed The extractor always returns a pandas DataFrame, be it empty. It enhances robustness and stability. v0.2.0 - 2022-05-09 Added aggregation submodule to handle the specifics of aggregating text blocs Base classes for better-defined modules Uniformise the columns to labels Add arbitrary contextual information Removed typer legacy dependency models submodule, which handled the configurations for Spark distribution (deferred to another package) specific orbis context, which was APHP-specific v0.1.0 - 2022-05-06 Inception ! Features spaCy-like configuration system Available classifiers : dummy.v1 , that classifies everything to body mask.v1 , for simple rule-based classification sklearn.v1 , that uses a Scikit-Learn pipeline random.v1 , to better sow chaos Merge different blocs together for easier visualisation Streamlit demo with visualisation","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v051-2022-07-26","text":"","title":"v0.5.1 - 2022-07-26"},{"location":"changelog/#changed","text":"Drop the pdf2image dependency, replacing it with pypdfium2 (easier installation)","title":"Changed"},{"location":"changelog/#v050-2022-07-25","text":"","title":"v0.5.0 - 2022-07-25"},{"location":"changelog/#changed_1","text":"Major refactoring of the library. Moved from concepts ( aggregation ) to plural names ( aggregators ).","title":"Changed"},{"location":"changelog/#v043-2022-07-20","text":"","title":"v0.4.3 - 2022-07-20"},{"location":"changelog/#fixed","text":"Multi page boxes alignment","title":"Fixed"},{"location":"changelog/#v042-2022-07-06","text":"","title":"v0.4.2 - 2022-07-06"},{"location":"changelog/#added","text":"package-resource.v1 in the misc registry","title":"Added"},{"location":"changelog/#v041-2022-06-14","text":"","title":"v0.4.1 - 2022-06-14"},{"location":"changelog/#fixed_1","text":"Remove importlib.metadata dependency, which led to issues with Python 3.7","title":"Fixed"},{"location":"changelog/#v040-2022-06-14","text":"","title":"v0.4.0 - 2022-06-14"},{"location":"changelog/#added_1","text":"Python 3.7 support, by relaxing dependency constraints Support for package-resource pipeline for sklearn-pipeline.v1","title":"Added"},{"location":"changelog/#v032-2022-06-03","text":"","title":"v0.3.2 - 2022-06-03"},{"location":"changelog/#added_2","text":"compare_results in visualisation","title":"Added"},{"location":"changelog/#v031-2022-06-02","text":"","title":"v0.3.1 - 2022-06-02"},{"location":"changelog/#fixed_2","text":"Rescale transform now keeps origin on top-left corner","title":"Fixed"},{"location":"changelog/#v030-2022-06-01","text":"","title":"v0.3.0 - 2022-06-01"},{"location":"changelog/#added_3","text":"Styles management within the extractor styled.v1 aggregator, to handle styles rescale.v1 transform, to go back to the original height and width","title":"Added"},{"location":"changelog/#changed_2","text":"Styles and text extraction is handled by the extractor directly The PDFMiner line object is not carried around any more","title":"Changed"},{"location":"changelog/#removed","text":"Outdated params entry in the EDS-PDF registry.","title":"Removed"},{"location":"changelog/#v022-2022-05-12","text":"","title":"v0.2.2 - 2022-05-12"},{"location":"changelog/#changed_3","text":"Fixed merge_lines bug when lines were empty Modified the demo consequently","title":"Changed"},{"location":"changelog/#v021-2022-05-09","text":"","title":"v0.2.1 - 2022-05-09"},{"location":"changelog/#changed_4","text":"The extractor always returns a pandas DataFrame, be it empty. It enhances robustness and stability.","title":"Changed"},{"location":"changelog/#v020-2022-05-09","text":"","title":"v0.2.0 - 2022-05-09"},{"location":"changelog/#added_4","text":"aggregation submodule to handle the specifics of aggregating text blocs Base classes for better-defined modules Uniformise the columns to labels Add arbitrary contextual information","title":"Added"},{"location":"changelog/#removed_1","text":"typer legacy dependency models submodule, which handled the configurations for Spark distribution (deferred to another package) specific orbis context, which was APHP-specific","title":"Removed"},{"location":"changelog/#v010-2022-05-06","text":"Inception !","title":"v0.1.0 - 2022-05-06"},{"location":"changelog/#features","text":"spaCy-like configuration system Available classifiers : dummy.v1 , that classifies everything to body mask.v1 , for simple rule-based classification sklearn.v1 , that uses a Scikit-Learn pipeline random.v1 , to better sow chaos Merge different blocs together for easier visualisation Streamlit demo with visualisation","title":"Features"},{"location":"concepts/","text":"Key Concepts The goal of EDS-PDF is to provide a framework for text extraction from PDF documents, along with some utilities and a few pipelines, stitched together by a robust configuration system powered by Thinc . Organisation The core object within EDS-PDF is the reader , which organises the extraction along four well-defined steps: The extraction step extracts text blocs from the PDF and compiles them into a pandas DataFrame object, where each row relates to a single bloc. The transformation step is optional. It computes user-defined transformation on the data, to provide the classification algorithm with additional features. The classification step categorises each bloc, typically between body , header , footer ... The aggregation step compiles the blocs together, exploiting the classification to re-create the original text. Data Structure EDS-PDF parses the PDF into a pandas DataFrame object where each row represents a text bloc. The DataFrame is carried all the way down to the aggregation step. The following columns are reserved: Column Description text Bloc text content page Page within the PDF (starting at 0) x0 Horizontal position of the top-left corner of the bloc bounding box x1 Horizontal position of the bottom-right corner of the bloc bounding box y0 Vertical position of the top-left corner of the bloc bounding box y1 Vertical position of the bottom-right corner of the bloc bounding box label Class of the bloc (eg body , header ...) Position of bloc bounding boxes The positional information (columns x0/x1/y0/y1 ) is normalised, and takes the top-left corner of the page as reference. Note that this contrasts with the PDF convention, which takes the bottom left corner as origin instead. Some transformations may create their own columns. It's your responsibility to verify that the column names do not override each other. We can review the different stages of the pipeline: Step Input Output Description Extraction PDF (bytes) DataFrame Extracts text blocs from the PDF Transformation DataFrame DataFrame Compute hand-defined transformations on the blocs Classification DataFrame DataFrame Categorises each bloc Aggregation DataFrame Dict Re-creates the original text Configuration Following the example of spaCy, EDS-PDF is organised around Explosion's catalogue library , enabling a powerful configuration system based on an extendable registry. The following catalogues are included within EDS-PDF: Section Description readers Top-level object, encapsulating a full EDS-PDF pipeline extractors Text bloc extraction models transforms Transformations that can be applied to each bloc before classification classifiers Classification routines (eg rule- or ml-based) misc Some miscellaneous utility functions Much like spaCy pipelines, EDS-PDF pipelines are meant to be reproducible and serialisable, such that the primary way to define a pipeline is through the configuration system. To wit, compare the API-based approach to the configuration-based approach (the two are strictly equivalent): API-based Configuration-based from edspdf import aggregation , reading , extraction , classification from pathlib import Path reader = reading . PdfReader ( extractor = extraction . PdfMinerExtractor (), classifier = classification . simple_mask_classifier_factory ( x0 = 0.2 , x1 = 0.9 , y0 = 0.3 , y1 = 0.6 , threshold = 0.1 , ), aggregator = aggregation . SimpleAggregation (), ) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n... config.cfg [reader] @ readers = \"pdf-reader.v1\" [reader.extractor] @ extractors = \"pdfminer.v1\" [reader.classifier] @ classifiers = \"mask.v1\" x0 = 0.2 x1 = 0.9 y0 = 0.3 y1 = 0.6 threshold = 0.1 [reader.aggregator] @ aggregators = \"simple.v1\" from edspdf import registry , Config from pathlib import Path config = Config () . from_disk ( \"config.cfg\" ) reader = registry . resolve ( config )[ \"reader\" ] # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n... The configuration-based approach strictly separates the definition of the pipeline to its application and avoids tucking away important configuration details. Changes to the pipeline are transparent as there is a single source of truth: the configuration file. For more information on the configuration system, refer to the documentations of Thinc and spaCy . Modularity and Extensibility EDS-PDF includes everything you need to get started on text extraction, and ships with a number of trainable classifiers. But it also makes it extremely easy to extend its functionalities by designing new pipelines.","title":"Key Concepts"},{"location":"concepts/#key-concepts","text":"The goal of EDS-PDF is to provide a framework for text extraction from PDF documents, along with some utilities and a few pipelines, stitched together by a robust configuration system powered by Thinc .","title":"Key Concepts"},{"location":"concepts/#organisation","text":"The core object within EDS-PDF is the reader , which organises the extraction along four well-defined steps: The extraction step extracts text blocs from the PDF and compiles them into a pandas DataFrame object, where each row relates to a single bloc. The transformation step is optional. It computes user-defined transformation on the data, to provide the classification algorithm with additional features. The classification step categorises each bloc, typically between body , header , footer ... The aggregation step compiles the blocs together, exploiting the classification to re-create the original text.","title":"Organisation"},{"location":"concepts/#data-structure","text":"EDS-PDF parses the PDF into a pandas DataFrame object where each row represents a text bloc. The DataFrame is carried all the way down to the aggregation step. The following columns are reserved: Column Description text Bloc text content page Page within the PDF (starting at 0) x0 Horizontal position of the top-left corner of the bloc bounding box x1 Horizontal position of the bottom-right corner of the bloc bounding box y0 Vertical position of the top-left corner of the bloc bounding box y1 Vertical position of the bottom-right corner of the bloc bounding box label Class of the bloc (eg body , header ...) Position of bloc bounding boxes The positional information (columns x0/x1/y0/y1 ) is normalised, and takes the top-left corner of the page as reference. Note that this contrasts with the PDF convention, which takes the bottom left corner as origin instead. Some transformations may create their own columns. It's your responsibility to verify that the column names do not override each other. We can review the different stages of the pipeline: Step Input Output Description Extraction PDF (bytes) DataFrame Extracts text blocs from the PDF Transformation DataFrame DataFrame Compute hand-defined transformations on the blocs Classification DataFrame DataFrame Categorises each bloc Aggregation DataFrame Dict Re-creates the original text","title":"Data Structure"},{"location":"concepts/#configuration","text":"Following the example of spaCy, EDS-PDF is organised around Explosion's catalogue library , enabling a powerful configuration system based on an extendable registry. The following catalogues are included within EDS-PDF: Section Description readers Top-level object, encapsulating a full EDS-PDF pipeline extractors Text bloc extraction models transforms Transformations that can be applied to each bloc before classification classifiers Classification routines (eg rule- or ml-based) misc Some miscellaneous utility functions Much like spaCy pipelines, EDS-PDF pipelines are meant to be reproducible and serialisable, such that the primary way to define a pipeline is through the configuration system. To wit, compare the API-based approach to the configuration-based approach (the two are strictly equivalent): API-based Configuration-based from edspdf import aggregation , reading , extraction , classification from pathlib import Path reader = reading . PdfReader ( extractor = extraction . PdfMinerExtractor (), classifier = classification . simple_mask_classifier_factory ( x0 = 0.2 , x1 = 0.9 , y0 = 0.3 , y1 = 0.6 , threshold = 0.1 , ), aggregator = aggregation . SimpleAggregation (), ) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n... config.cfg [reader] @ readers = \"pdf-reader.v1\" [reader.extractor] @ extractors = \"pdfminer.v1\" [reader.classifier] @ classifiers = \"mask.v1\" x0 = 0.2 x1 = 0.9 y0 = 0.3 y1 = 0.6 threshold = 0.1 [reader.aggregator] @ aggregators = \"simple.v1\" from edspdf import registry , Config from pathlib import Path config = Config () . from_disk ( \"config.cfg\" ) reader = registry . resolve ( config )[ \"reader\" ] # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n... The configuration-based approach strictly separates the definition of the pipeline to its application and avoids tucking away important configuration details. Changes to the pipeline are transparent as there is a single source of truth: the configuration file. For more information on the configuration system, refer to the documentations of Thinc and spaCy .","title":"Configuration"},{"location":"concepts/#modularity-and-extensibility","text":"EDS-PDF includes everything you need to get started on text extraction, and ships with a number of trainable classifiers. But it also makes it extremely easy to extend its functionalities by designing new pipelines.","title":"Modularity and Extensibility"},{"location":"contributing/","text":"Contributing to EDS-PDF We welcome contributions ! There are many ways to help. For example, you can: Help us track bugs by filing issues Suggest and help prioritise new functionalities Help us make the library as straightforward as possible, by simply asking questions on whatever does not seem clear to you. Development installation To be able to run the test suite and develop your own pipeline, you should clone the repo and install it locally. We use Poetry to manage dependencies. See the installation instructions . color:gray # Clone the repository and change directory $ git clone ssh://git@github.com/aphp/edspdf.git ---> 100% $ cd edspdf color:gray # Install the dependencies $ poetry install To make sure the pipeline will not fail because of formatting errors, we added pre-commit hooks using the pre-commit Python library. To use it, simply install it: $ pre-commit install The pre-commit hooks defined in the configuration will automatically run when you commit your changes, letting you know if something went wrong. The hooks only run on staged changes. To force-run it on all files, run: $ pre-commit run --all-files ---> 100% color:green All good ! Proposing a merge request At the very least, your changes should : Be well-documented ; Pass every tests, and preferably implement its own ; Follow the style guide. Testing your code We use the Pytest test suite. The following command will run the test suite. Writing your own tests is encouraged ! poetry run pytest Should your contribution propose a bug fix, we require the bug be thoroughly tested. Style Guide We use Black to reformat the code. While other formatter only enforce PEP8 compliance, Black also makes the code uniform. In short : Black reformats entire files in place. It is not configurable. Moreover, the CI/CD pipeline enforces a number of checks on the \"quality\" of the code. To wit, non black-formatted code will make the test pipeline fail. We use pre-commit to keep our codebase clean. Refer to the development install tutorial for tips on how to format your files automatically. Most modern editors propose extensions that will format files on save. Documentation Make sure to document your improvements, both within the code with comprehensive docstrings, as well as in the documentation itself if need be. We use MkDocs for EDS-Toolbox's documentation. You can checkout the changes you make with: color:gray # Run the documentation $ mkdocs serve Go to localhost:8000 to see your changes. MkDocs watches for changes in the documentation folder and automatically reloads the page.","title":"Contributing to EDS-PDF"},{"location":"contributing/#contributing-to-eds-pdf","text":"We welcome contributions ! There are many ways to help. For example, you can: Help us track bugs by filing issues Suggest and help prioritise new functionalities Help us make the library as straightforward as possible, by simply asking questions on whatever does not seem clear to you.","title":"Contributing to EDS-PDF"},{"location":"contributing/#development-installation","text":"To be able to run the test suite and develop your own pipeline, you should clone the repo and install it locally. We use Poetry to manage dependencies. See the installation instructions . color:gray # Clone the repository and change directory $ git clone ssh://git@github.com/aphp/edspdf.git ---> 100% $ cd edspdf color:gray # Install the dependencies $ poetry install To make sure the pipeline will not fail because of formatting errors, we added pre-commit hooks using the pre-commit Python library. To use it, simply install it: $ pre-commit install The pre-commit hooks defined in the configuration will automatically run when you commit your changes, letting you know if something went wrong. The hooks only run on staged changes. To force-run it on all files, run: $ pre-commit run --all-files ---> 100% color:green All good !","title":"Development installation"},{"location":"contributing/#proposing-a-merge-request","text":"At the very least, your changes should : Be well-documented ; Pass every tests, and preferably implement its own ; Follow the style guide.","title":"Proposing a merge request"},{"location":"contributing/#testing-your-code","text":"We use the Pytest test suite. The following command will run the test suite. Writing your own tests is encouraged ! poetry run pytest Should your contribution propose a bug fix, we require the bug be thoroughly tested.","title":"Testing your code"},{"location":"contributing/#style-guide","text":"We use Black to reformat the code. While other formatter only enforce PEP8 compliance, Black also makes the code uniform. In short : Black reformats entire files in place. It is not configurable. Moreover, the CI/CD pipeline enforces a number of checks on the \"quality\" of the code. To wit, non black-formatted code will make the test pipeline fail. We use pre-commit to keep our codebase clean. Refer to the development install tutorial for tips on how to format your files automatically. Most modern editors propose extensions that will format files on save.","title":"Style Guide"},{"location":"contributing/#documentation","text":"Make sure to document your improvements, both within the code with comprehensive docstrings, as well as in the documentation itself if need be. We use MkDocs for EDS-Toolbox's documentation. You can checkout the changes you make with: color:gray # Run the documentation $ mkdocs serve Go to localhost:8000 to see your changes. MkDocs watches for changes in the documentation folder and automatically reloads the page.","title":"Documentation"},{"location":"roadmap/","text":"Roadmap Style extraction spaCy classifier, to use richer text representations Add complete serialisation capabilities, to save a full pipeline to disk. Draw inspiration from spaCy, which took great care to solve these issues: add save and load methods to every pipeline component Add training capabilities with a CLI to automate the annotation/preparation/training loop. Again, draw inspiration from spaCy, and maybe add the notion of a TrainableClassifier ... Multiple-column extraction Table detector Integrate third-party OCR module Drop pandas DataFrame in favour of a Cython wrapper around PDF documents?","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"Style extraction spaCy classifier, to use richer text representations Add complete serialisation capabilities, to save a full pipeline to disk. Draw inspiration from spaCy, which took great care to solve these issues: add save and load methods to every pipeline component Add training capabilities with a CLI to automate the annotation/preparation/training loop. Again, draw inspiration from spaCy, and maybe add the notion of a TrainableClassifier ... Multiple-column extraction Table detector Integrate third-party OCR module Drop pandas DataFrame in favour of a Cython wrapper around PDF documents?","title":"Roadmap"},{"location":"modules/","text":"Overview EDS-PDF is organised into modules that handle each step of the extraction process. The following functions are registered: Section Function extractors pdfminer.v1 aggregators simple.v1 aggregators styled.v1 readers pdf-reader.v1 classifiers dummy.v1 classifiers mask.v1 classifiers custom_masks.v1 classifiers random.v1 classifiers sklearn-pipeline.v1 transforms chain.v1 transforms telephone.v1 transforms dates.v1 transforms dimensions.v1 transforms rescale.v1 misc package-resource.v1","title":"Overview"},{"location":"modules/#overview","text":"EDS-PDF is organised into modules that handle each step of the extraction process. The following functions are registered: Section Function extractors pdfminer.v1 aggregators simple.v1 aggregators styled.v1 readers pdf-reader.v1 classifiers dummy.v1 classifiers mask.v1 classifiers custom_masks.v1 classifiers random.v1 classifiers sklearn-pipeline.v1 transforms chain.v1 transforms telephone.v1 transforms dates.v1 transforms dimensions.v1 transforms rescale.v1 misc package-resource.v1","title":"Overview"},{"location":"modules/aggregation/","text":"Aggregation The aggregation step compiles extracted text blocs together according to their detected class. Method Description simple.v1 Returns a dictionary with one key for each detected class styled.v1 Returns the same dictionary, as well as the information on styles","title":"Aggregation"},{"location":"modules/aggregation/#aggregation","text":"The aggregation step compiles extracted text blocs together according to their detected class. Method Description simple.v1 Returns a dictionary with one key for each detected class styled.v1 Returns the same dictionary, as well as the information on styles","title":"Aggregation"},{"location":"modules/extraction/","text":"Extraction The extraction phase consists of reading the PDF document and gather text blocs, along with their dimensions and position within the document. Said blocs will go on to the classification phase to separate the body from the rest. Method Description pdfminer.v1 Text-based PDF extraction using PDFMiner Text-based PDF We provide a unique extractor architecture, that is based on the PDFMiner library. Be sure to have a look at their documentation, especially the part providing a bird's eye view of the PDF extraction process . Image-based PDF Image-based PDF documents require an OCR 1 step, which is not natively supported by EDS-PDF. However, you can easily extend EDS-PDF by adding such a method to the registry, and using that extractor function in place of pdfminer.v1 . Optical Character Recognition, or OCR, is the process of converting an image of text into a text format. \u21a9","title":"Extraction"},{"location":"modules/extraction/#extraction","text":"The extraction phase consists of reading the PDF document and gather text blocs, along with their dimensions and position within the document. Said blocs will go on to the classification phase to separate the body from the rest. Method Description pdfminer.v1 Text-based PDF extraction using PDFMiner","title":"Extraction"},{"location":"modules/extraction/#text-based-pdf","text":"We provide a unique extractor architecture, that is based on the PDFMiner library. Be sure to have a look at their documentation, especially the part providing a bird's eye view of the PDF extraction process .","title":"Text-based PDF"},{"location":"modules/extraction/#image-based-pdf","text":"Image-based PDF documents require an OCR 1 step, which is not natively supported by EDS-PDF. However, you can easily extend EDS-PDF by adding such a method to the registry, and using that extractor function in place of pdfminer.v1 . Optical Character Recognition, or OCR, is the process of converting an image of text into a text format. \u21a9","title":"Image-based PDF"},{"location":"modules/transforms/","text":"Transforms The transformation phase consists of rule-based transformations applied to the text blocs in order to provide the classification algorithm with more information. Method Description chain.v1 Chain a sequence of transforms together telephone.v1 Creates a new column, containing the number of phone numbers dates.v1 Creates a new column, containing the number of dates dimensions.v1 Creates new columns with the width, height and area of the bloc rescale.v1 Rescale the bloc dimensions to the original height and width","title":"Transforms"},{"location":"modules/transforms/#transforms","text":"The transformation phase consists of rule-based transformations applied to the text blocs in order to provide the classification algorithm with more information. Method Description chain.v1 Chain a sequence of transforms together telephone.v1 Creates a new column, containing the number of phone numbers dates.v1 Creates a new column, containing the number of dates dimensions.v1 Creates new columns with the width, height and area of the bloc rescale.v1 Rescale the bloc dimensions to the original height and width","title":"Transforms"},{"location":"modules/classification/","text":"Classifiers We developed EDS-PDF with modularity in mind. To that end, you can choose between multiple classification methods. Method Description mask.v1 Simple rule-based classification sklearn.v1 Machine-learning-base classification using a Scikit-learn pipeline dummy.v1 Dummy classifier, for testing purposes. Classifies every bloc to body random.v1 To sow chaos","title":"Classifiers"},{"location":"modules/classification/#classifiers","text":"We developed EDS-PDF with modularity in mind. To that end, you can choose between multiple classification methods. Method Description mask.v1 Simple rule-based classification sklearn.v1 Machine-learning-base classification using a Scikit-learn pipeline dummy.v1 Dummy classifier, for testing purposes. Classifies every bloc to body random.v1 To sow chaos","title":"Classifiers"},{"location":"modules/classification/mask/","text":"Mask Classification We developed a simple classifier that roughly uses the same strategy as PDFBox, namely: define a \"mask\" on the PDF documents ; keep every text bloc within that mask, tag everything else as pollution. Factories Two factories are available in the classifiers registry: mask.v1 and custom_masks.v1 . mask.v1 The simplest form. You define the mask, everything else is tagged as a pollution. Example configuration : [classifier] @ classifiers = \"mask.v1\" x0 = 0.1 y0 = 0.1 x1 = 0.9 y1 = 0.9 threshold = 0.9 custom_masks.v1 A generalisation, wherein the user defines a number of regions. The following configuration produces exactly the same classifier as mask.v1 example above. [classifier] @ classifiers = \"custom_masks.v1\" [classifier.body] label = \"body\" x0 = 0.1 y0 = 0.1 x1 = 0.9 y1 = 0.9 threshold = 0.9 The following configuration defines a header region. [classifier] @ classifiers = \"custom_masks.v1\" [classifier.header] label = \"header\" x0 = 0.1 y0 = 0.1 x1 = 0.9 y1 = 0.3 threshold = 0.9 [classifier.body] label = \"body\" x0 = 0.1 y0 = 0.3 x1 = 0.9 y1 = 0.9 threshold = 0.9 Any bloc that is not part of a mask is tagged as pollution .","title":"Mask Classification"},{"location":"modules/classification/mask/#mask-classification","text":"We developed a simple classifier that roughly uses the same strategy as PDFBox, namely: define a \"mask\" on the PDF documents ; keep every text bloc within that mask, tag everything else as pollution.","title":"Mask Classification"},{"location":"modules/classification/mask/#factories","text":"Two factories are available in the classifiers registry: mask.v1 and custom_masks.v1 .","title":"Factories"},{"location":"modules/classification/mask/#maskv1","text":"The simplest form. You define the mask, everything else is tagged as a pollution. Example configuration : [classifier] @ classifiers = \"mask.v1\" x0 = 0.1 y0 = 0.1 x1 = 0.9 y1 = 0.9 threshold = 0.9","title":"mask.v1"},{"location":"modules/classification/mask/#custom_masksv1","text":"A generalisation, wherein the user defines a number of regions. The following configuration produces exactly the same classifier as mask.v1 example above. [classifier] @ classifiers = \"custom_masks.v1\" [classifier.body] label = \"body\" x0 = 0.1 y0 = 0.1 x1 = 0.9 y1 = 0.9 threshold = 0.9 The following configuration defines a header region. [classifier] @ classifiers = \"custom_masks.v1\" [classifier.header] label = \"header\" x0 = 0.1 y0 = 0.1 x1 = 0.9 y1 = 0.3 threshold = 0.9 [classifier.body] label = \"body\" x0 = 0.1 y0 = 0.3 x1 = 0.9 y1 = 0.9 threshold = 0.9 Any bloc that is not part of a mask is tagged as pollution .","title":"custom_masks.v1"},{"location":"modules/classification/sklearn/","text":"Sklearn We provide a helper to use a Scikit-Learn pipeline for the classification task. Save your pipeline with joblib (as advised in the Scikit-Learn documentation ), and use the helper registered as sklearn.v1 . It expects a path to your saved configuration. [classifier] @ classifiers = \"sklearn.v1\" path = \"pipeline.joblib\"","title":"Sklearn"},{"location":"modules/classification/sklearn/#sklearn","text":"We provide a helper to use a Scikit-Learn pipeline for the classification task. Save your pipeline with joblib (as advised in the Scikit-Learn documentation ), and use the helper registered as sklearn.v1 . It expects a path to your saved configuration. [classifier] @ classifiers = \"sklearn.v1\" path = \"pipeline.joblib\"","title":"Sklearn"},{"location":"recipes/","text":"EDS-PDF Recipes This section goes over a few use-cases for PDF extraction. It is meant as a more hands-on tutorial to get a grip on the library.","title":"EDS-PDF Recipes"},{"location":"recipes/#eds-pdf-recipes","text":"This section goes over a few use-cases for PDF extraction. It is meant as a more hands-on tutorial to get a grip on the library.","title":"EDS-PDF Recipes"},{"location":"recipes/annotation/","text":"PDF Annotation In this section, we will cover one methodology to annotate PDF documents. Data annotation at AP-HP's CDW At AP-HP's CDW 1 , we recently moved away from a rule- and Java-based PDF extraction pipeline (using PDFBox) to one using EDS-PDF. Hence, EDS-PDF is used in production, helping extract text from around 100k PDF documents every day. To train our pipeline presently in production, we annotated around 270 documents , and reached a f1-score of 91% on the body classification. Preparing the data for annotation We will frame the annotation phase as an image segmentation task, where annotators are asked to draw bounding boxes around the different sections. Hence, the very first step is to convert PDF documents to images. We suggest using the library pdf2image for that step. The following script will convert the PDF documents located in a data/pdfs directory to PNG images inside the data/images folder. import pdf2image from pathlib import Path DATA_DIR = Path ( \"data\" ) PDF_DIR = DATA_DIR / \"pdfs\" IMAGE_DIR = DATA_DIR / \"images\" for pdf in PDF_DIR . glob ( \"*.pdf\" ): imgs = pdf2image . convert_from_bytes ( pdf ) for page , img in enumerate ( imgs ): path = IMAGE_DIR / f \" { pdf . stem } _ { page } .png\" img . save ( path ) You can use any annotation tool to annotate the images. If you're looking for a simple way to annotate from within a Jupyter Notebook, ipyannotations might be a good fit. You will need to post-process the output to convert the annotations to the following format: Key Description page Page within the PDF (0-indexed) X0 Horizontal position of the top-left corner of the bounding box X1 Horizontal position of the bottom-right corner of the bounding box Y0 Vertical position of the top-left corner of the bounding box Y1 Vertical position of the bottom-right corner of the bounding box label Class of the bounding box (eg body , header ...) All dimensions should be normalised by the height and width of the page. Saving the dataset Once the annotation phase is complete, make sure the train/test split is performed once and for all when you create the dataset. We suggest the following structure: Directory structure dataset/ \u251c\u2500\u2500 train/ \u2502 \u251c\u2500\u2500 <note_id_1>.pdf \u2502 \u251c\u2500\u2500 <note_id_1>.json \u2502 \u251c\u2500\u2500 <note_id_2>.pdf \u2502 \u251c\u2500\u2500 <note_id_2>.json \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 test/ \u251c\u2500\u2500 <note_id_n>.pdf \u251c\u2500\u2500 <note_id_n>.json \u2514\u2500\u2500 ... Where the normalised annotation resides in a JSON file living next to the related PDF, and uses the following schema: Key Description note_id Reference to the document <properties> Optional property of the document itself annotations List of annotations, following the schema above This structure presents the advantage of being machine- and human-friendly. The JSON file contains annotated regions as well as any document property that could be useful to adapt the pipeline (typically for the classification step). Extracting annotations The following snippet extracts the annotations into a workable format: from pathlib import Path import pandas as pd def get_annotations ( directory : Path , ) -> pd . DataFrame : \"\"\" Read annotations from the dataset directory. Parameters ---------- directory : Path Dataset directory Returns ------- pd.DataFrame Pandas DataFrame containing the annotations. \"\"\" dfs = [] iterator = tqdm ( list ( directory . glob ( \"*.json\" ))) for path in iterator : meta = json . loads ( path . read_text ()) df = pd . DataFrame . from_records ( meta . pop ( \"annotations\" )) for k , v in meta . items (): # (1) df [ k ] = v dfs . append ( df ) return pd . concat ( dfs ) train_path = Path ( \"dataset/train\" ) annotations = get_annotations ( train_path ) Add a column for each additional property saved in the dataset. The annotations compiled this way can be used to train a pipeline. See the trained pipeline recipe for more detail. Greater Paris University Hospital's Clinical Data Warehouse \u21a9","title":"PDF Annotation"},{"location":"recipes/annotation/#pdf-annotation","text":"In this section, we will cover one methodology to annotate PDF documents. Data annotation at AP-HP's CDW At AP-HP's CDW 1 , we recently moved away from a rule- and Java-based PDF extraction pipeline (using PDFBox) to one using EDS-PDF. Hence, EDS-PDF is used in production, helping extract text from around 100k PDF documents every day. To train our pipeline presently in production, we annotated around 270 documents , and reached a f1-score of 91% on the body classification.","title":"PDF Annotation"},{"location":"recipes/annotation/#preparing-the-data-for-annotation","text":"We will frame the annotation phase as an image segmentation task, where annotators are asked to draw bounding boxes around the different sections. Hence, the very first step is to convert PDF documents to images. We suggest using the library pdf2image for that step. The following script will convert the PDF documents located in a data/pdfs directory to PNG images inside the data/images folder. import pdf2image from pathlib import Path DATA_DIR = Path ( \"data\" ) PDF_DIR = DATA_DIR / \"pdfs\" IMAGE_DIR = DATA_DIR / \"images\" for pdf in PDF_DIR . glob ( \"*.pdf\" ): imgs = pdf2image . convert_from_bytes ( pdf ) for page , img in enumerate ( imgs ): path = IMAGE_DIR / f \" { pdf . stem } _ { page } .png\" img . save ( path ) You can use any annotation tool to annotate the images. If you're looking for a simple way to annotate from within a Jupyter Notebook, ipyannotations might be a good fit. You will need to post-process the output to convert the annotations to the following format: Key Description page Page within the PDF (0-indexed) X0 Horizontal position of the top-left corner of the bounding box X1 Horizontal position of the bottom-right corner of the bounding box Y0 Vertical position of the top-left corner of the bounding box Y1 Vertical position of the bottom-right corner of the bounding box label Class of the bounding box (eg body , header ...) All dimensions should be normalised by the height and width of the page.","title":"Preparing the data for annotation"},{"location":"recipes/annotation/#saving-the-dataset","text":"Once the annotation phase is complete, make sure the train/test split is performed once and for all when you create the dataset. We suggest the following structure: Directory structure dataset/ \u251c\u2500\u2500 train/ \u2502 \u251c\u2500\u2500 <note_id_1>.pdf \u2502 \u251c\u2500\u2500 <note_id_1>.json \u2502 \u251c\u2500\u2500 <note_id_2>.pdf \u2502 \u251c\u2500\u2500 <note_id_2>.json \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 test/ \u251c\u2500\u2500 <note_id_n>.pdf \u251c\u2500\u2500 <note_id_n>.json \u2514\u2500\u2500 ... Where the normalised annotation resides in a JSON file living next to the related PDF, and uses the following schema: Key Description note_id Reference to the document <properties> Optional property of the document itself annotations List of annotations, following the schema above This structure presents the advantage of being machine- and human-friendly. The JSON file contains annotated regions as well as any document property that could be useful to adapt the pipeline (typically for the classification step).","title":"Saving the dataset"},{"location":"recipes/annotation/#extracting-annotations","text":"The following snippet extracts the annotations into a workable format: from pathlib import Path import pandas as pd def get_annotations ( directory : Path , ) -> pd . DataFrame : \"\"\" Read annotations from the dataset directory. Parameters ---------- directory : Path Dataset directory Returns ------- pd.DataFrame Pandas DataFrame containing the annotations. \"\"\" dfs = [] iterator = tqdm ( list ( directory . glob ( \"*.json\" ))) for path in iterator : meta = json . loads ( path . read_text ()) df = pd . DataFrame . from_records ( meta . pop ( \"annotations\" )) for k , v in meta . items (): # (1) df [ k ] = v dfs . append ( df ) return pd . concat ( dfs ) train_path = Path ( \"dataset/train\" ) annotations = get_annotations ( train_path ) Add a column for each additional property saved in the dataset. The annotations compiled this way can be used to train a pipeline. See the trained pipeline recipe for more detail. Greater Paris University Hospital's Clinical Data Warehouse \u21a9","title":"Extracting annotations"},{"location":"recipes/extension/","text":"Extending EDS-PDF EDS-PDF is organised around a function registry powered by catalogue, which plays extremely well with Thinc's configuration system. The result is a powerful framework that is easy to extend - and we'll see how in this section. For this recipe, let's imagine we're not entirely satisfied with the aggregation proposed by EDS-PDF. For instance, we might want an aggregator that outputs the text in markdown format. Note Properly converting to markdown is no easy task. For this example, we will limit ourselves to detecting italics sections. Developing the new aggregator Our aggregator will inherit from the StyledAggregator , and use the style to detect italics and bold sections. markdown_aggregator.py from edspdf import registry from typing import Any , Dict from edspdf.aggregation.styled import StyledAggregator def process_style ( style : Dict [ str , Any ]) -> bool , bool , int , int : bold = \"bold\" in style [ \"style\" ] . lower () italics = ( not style [ \"upright\" ]) or ( \"italics\" in style [ \"style\" ] . lower ()) return bold , italics , style [ \"start\" ], style [ \"end\" ] @registry . aggregators . register ( \"markdown.v1\" ) # (1) class MarkdownAggregator ( SimpleAggregator ): def aggregate ( self , lines : pd . DataFrame ) -> str : # (2) texts , styles = super ( self ) . aggregate ( lines ) body = texts . get ( \"body\" , \"\" ) style = styles . get ( \"body\" , []) fragments = [] for s in style : bold , italics , start , end = process_style ( s ) text = body [ start : end ] if bold : text = f \"** { text } **\" if italics : text = f \"_ { text } _\" fragments . append ( text ) return \"\" . join ( fragments ) The new aggregator is registered via this line The new aggregator redefines the aggregate method. It will output a single string, corresponding to the markdown-formatted output. That's it! You can use this new aggregator with the API: from edspdf import reading , extraction , classification from markdown_aggregator import MarkdownAggregator # (1) from pathlib import Path reader = reading . PdfReader ( extractor = extraction . PdfMinerExtractor (), classifier = classification . simple_mask_classifier_factory ( x0 = 0.2 , x1 = 0.9 , y0 = 0.3 , y1 = 0.6 , threshold = 0.1 , ), aggregator = MarkdownAggregator (), ) We're importing the aggregator that we just defined. It all works relatively smoothly! Making the aggregator discoverable Now, how can we instantiate the pipeline using the configuration system? The registry needs to be aware of the new function, but we shouldn't have to import mardown_aggregator.py just so that the module is registered as a side-effect... Catalogue solves this problem by using Python entry points . pyproject.toml (Poetry) setup.py [tool.poetry.plugins.\"edspdf_aggregators\"] \"custom.markdown.v1\" = \"markdown_aggregator:MarkdownAggregator\" from setuptools import setup setup ( name = \"edspdf-markdown\" , entry_points = { \"edspdf_aggregators\" : [ \"custom.markdown.v1 = markdown_aggregator:MarkdownAggregator\" ] }, ) By declaring the new aggregator as an entrypoint, it will become discoverable by EDS-PDF as long as it is installed in your environment!","title":"Extending EDS-PDF"},{"location":"recipes/extension/#extending-eds-pdf","text":"EDS-PDF is organised around a function registry powered by catalogue, which plays extremely well with Thinc's configuration system. The result is a powerful framework that is easy to extend - and we'll see how in this section. For this recipe, let's imagine we're not entirely satisfied with the aggregation proposed by EDS-PDF. For instance, we might want an aggregator that outputs the text in markdown format. Note Properly converting to markdown is no easy task. For this example, we will limit ourselves to detecting italics sections.","title":"Extending EDS-PDF"},{"location":"recipes/extension/#developing-the-new-aggregator","text":"Our aggregator will inherit from the StyledAggregator , and use the style to detect italics and bold sections. markdown_aggregator.py from edspdf import registry from typing import Any , Dict from edspdf.aggregation.styled import StyledAggregator def process_style ( style : Dict [ str , Any ]) -> bool , bool , int , int : bold = \"bold\" in style [ \"style\" ] . lower () italics = ( not style [ \"upright\" ]) or ( \"italics\" in style [ \"style\" ] . lower ()) return bold , italics , style [ \"start\" ], style [ \"end\" ] @registry . aggregators . register ( \"markdown.v1\" ) # (1) class MarkdownAggregator ( SimpleAggregator ): def aggregate ( self , lines : pd . DataFrame ) -> str : # (2) texts , styles = super ( self ) . aggregate ( lines ) body = texts . get ( \"body\" , \"\" ) style = styles . get ( \"body\" , []) fragments = [] for s in style : bold , italics , start , end = process_style ( s ) text = body [ start : end ] if bold : text = f \"** { text } **\" if italics : text = f \"_ { text } _\" fragments . append ( text ) return \"\" . join ( fragments ) The new aggregator is registered via this line The new aggregator redefines the aggregate method. It will output a single string, corresponding to the markdown-formatted output. That's it! You can use this new aggregator with the API: from edspdf import reading , extraction , classification from markdown_aggregator import MarkdownAggregator # (1) from pathlib import Path reader = reading . PdfReader ( extractor = extraction . PdfMinerExtractor (), classifier = classification . simple_mask_classifier_factory ( x0 = 0.2 , x1 = 0.9 , y0 = 0.3 , y1 = 0.6 , threshold = 0.1 , ), aggregator = MarkdownAggregator (), ) We're importing the aggregator that we just defined. It all works relatively smoothly!","title":"Developing the new aggregator"},{"location":"recipes/extension/#making-the-aggregator-discoverable","text":"Now, how can we instantiate the pipeline using the configuration system? The registry needs to be aware of the new function, but we shouldn't have to import mardown_aggregator.py just so that the module is registered as a side-effect... Catalogue solves this problem by using Python entry points . pyproject.toml (Poetry) setup.py [tool.poetry.plugins.\"edspdf_aggregators\"] \"custom.markdown.v1\" = \"markdown_aggregator:MarkdownAggregator\" from setuptools import setup setup ( name = \"edspdf-markdown\" , entry_points = { \"edspdf_aggregators\" : [ \"custom.markdown.v1 = markdown_aggregator:MarkdownAggregator\" ] }, ) By declaring the new aggregator as an entrypoint, it will become discoverable by EDS-PDF as long as it is installed in your environment!","title":"Making the aggregator discoverable"},{"location":"recipes/rules/","text":"Rule-based Extraction Let's create a rule-based extractor for PDF documents. Note This pipeline will likely perform poorly as soon as your PDF documents come in varied forms. In that case, even a very simple trained pipeline may give you a substantial performance boost (see next section ). First, download this example PDF . We will use the following configuration: config.cfg [reader] @ readers = \"pdf-reader.v1\" # (1) [reader.extractor] @ extractors = \"pdfminer.v1\" # (2) [reader.classifier] @ classifiers = \"mask.v1\" # (3) x0 = 0.2 x1 = 0.9 y0 = 0.3 y1 = 0.6 threshold = 0.1 [reader.aggregator] @ aggregators = \"styled.v1\" # (4) This is the top-level object, which organises the entire extraction process. Here we use the provided text-based extractor, based on the PDFMiner library This is where we define the rule-based classifier. Here, we use a \"mask\", meaning that every text bloc that falls within the boundaries will be assigned the body label, everything else will be tagged as pollution. This aggregator returns a tuple of dictionaries. The first contains compiled text for each label, the second exports their style. Save the configuration as config.cfg and run the following snippet: import edspdf from pathlib import Path reader = edspdf . load ( \"config.cfg\" ) # (1) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts , styles = reader ( pdf ) This code will output the following results: Visualisation Extracted Text Extracted Style Cher Pr ABC, Cher DEF, Nous souhaitons remercier le CSE pour son avis favorable quant \u00e0 l\u2019acc\u00e8s aux donn\u00e9es de l\u2019Entrep\u00f4t de Donn\u00e9es de Sant\u00e9 du projet n\u00b0 XXXX. Nous avons bien pris connaissance des conditions requises pour cet avis favorable, c\u2019est pourquoi nous nous engageons par la pr\u00e9sente \u00e0 : \u2022 Informer individuellement les patients concern\u00e9s par la recherche, admis \u00e0 l'AP-HP avant juillet 2017, sortis vivants, et non r\u00e9admis depuis. \u2022 Effectuer une demande d'autorisation \u00e0 la CNIL en cas d'appariement avec d\u2019autres cohortes. Bien cordialement, The start and end columns refer to the character indices within the extracted text. fontname font style size upright x0 x1 y0 y1 start end BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.4949 0.3012 0.3130 0 22 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.8024 0.3488 0.3606 24 90 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.8024 0.8066 0.3488 0.3606 90 91 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.8067 0.9572 0.3488 0.3606 91 111 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3030 0.3069 0.3655 0.3773 112 113 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.3069 0.3111 0.3655 0.3773 113 114 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3111 0.6476 0.3655 0.3773 114 161 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.9327 0.3893 0.4011 163 247 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.9327 0.9369 0.3893 0.4011 247 248 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.9369 0.9572 0.3893 0.4011 248 251 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3030 0.6440 0.4060 0.4178 252 300 SymbolMT SymbolMT Normal 9.9600 True 0.3444 0.3521 0.4299 0.4418 302 303 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.9568 0.4303 0.4422 304 386 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.7544 0.4470 0.4588 387 445 SymbolMT SymbolMT Normal 9.9600 True 0.3444 0.3521 0.4710 0.4828 447 448 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.9096 0.4714 0.4832 449 523 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.9097 0.9139 0.4714 0.4832 523 524 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.9139 0.9572 0.4714 0.4832 524 530 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.4389 0.4882 0.5000 531 540 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.4678 0.5357 0.5475 542 560","title":"Rule-based Extraction"},{"location":"recipes/rules/#rule-based-extraction","text":"Let's create a rule-based extractor for PDF documents. Note This pipeline will likely perform poorly as soon as your PDF documents come in varied forms. In that case, even a very simple trained pipeline may give you a substantial performance boost (see next section ). First, download this example PDF . We will use the following configuration: config.cfg [reader] @ readers = \"pdf-reader.v1\" # (1) [reader.extractor] @ extractors = \"pdfminer.v1\" # (2) [reader.classifier] @ classifiers = \"mask.v1\" # (3) x0 = 0.2 x1 = 0.9 y0 = 0.3 y1 = 0.6 threshold = 0.1 [reader.aggregator] @ aggregators = \"styled.v1\" # (4) This is the top-level object, which organises the entire extraction process. Here we use the provided text-based extractor, based on the PDFMiner library This is where we define the rule-based classifier. Here, we use a \"mask\", meaning that every text bloc that falls within the boundaries will be assigned the body label, everything else will be tagged as pollution. This aggregator returns a tuple of dictionaries. The first contains compiled text for each label, the second exports their style. Save the configuration as config.cfg and run the following snippet: import edspdf from pathlib import Path reader = edspdf . load ( \"config.cfg\" ) # (1) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts , styles = reader ( pdf ) This code will output the following results: Visualisation Extracted Text Extracted Style Cher Pr ABC, Cher DEF, Nous souhaitons remercier le CSE pour son avis favorable quant \u00e0 l\u2019acc\u00e8s aux donn\u00e9es de l\u2019Entrep\u00f4t de Donn\u00e9es de Sant\u00e9 du projet n\u00b0 XXXX. Nous avons bien pris connaissance des conditions requises pour cet avis favorable, c\u2019est pourquoi nous nous engageons par la pr\u00e9sente \u00e0 : \u2022 Informer individuellement les patients concern\u00e9s par la recherche, admis \u00e0 l'AP-HP avant juillet 2017, sortis vivants, et non r\u00e9admis depuis. \u2022 Effectuer une demande d'autorisation \u00e0 la CNIL en cas d'appariement avec d\u2019autres cohortes. Bien cordialement, The start and end columns refer to the character indices within the extracted text. fontname font style size upright x0 x1 y0 y1 start end BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.4949 0.3012 0.3130 0 22 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.8024 0.3488 0.3606 24 90 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.8024 0.8066 0.3488 0.3606 90 91 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.8067 0.9572 0.3488 0.3606 91 111 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3030 0.3069 0.3655 0.3773 112 113 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.3069 0.3111 0.3655 0.3773 113 114 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3111 0.6476 0.3655 0.3773 114 161 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.9327 0.3893 0.4011 163 247 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.9327 0.9369 0.3893 0.4011 247 248 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.9369 0.9572 0.3893 0.4011 248 251 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3030 0.6440 0.4060 0.4178 252 300 SymbolMT SymbolMT Normal 9.9600 True 0.3444 0.3521 0.4299 0.4418 302 303 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.9568 0.4303 0.4422 304 386 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.7544 0.4470 0.4588 387 445 SymbolMT SymbolMT Normal 9.9600 True 0.3444 0.3521 0.4710 0.4828 447 448 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.9096 0.4714 0.4832 449 523 BCDHEE+Calibri BCDHEE+Calibri Normal 9.9600 True 0.9097 0.9139 0.4714 0.4832 523 524 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.9139 0.9572 0.4714 0.4832 524 530 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3746 0.4389 0.4882 0.5000 531 540 BCDFEE+Calibri BCDFEE+Calibri Normal 9.9600 True 0.3389 0.4678 0.5357 0.5475 542 560","title":"Rule-based Extraction"},{"location":"recipes/sklearn/","text":"Trained Pipeline with Scikit-Learn In this section, we'll see how we can train a machine-learning based classifier to get better performances. In this example, we will use a Scikit-Learn pipeline . Warning Scikit-Learn is ill-equipped to deal with text data. As such, it is not the best candidate to provide an effective classification method. However, it can still perform quite well and remains a good place to start tinkering with the inner workings of EDS-PDF. PDF annotation See the PDF annotation recipe for one annotation methodology. For the rest of this recipe, we will consider that the dataset follows the same structure. Pipeline definition Let's use the following pipeline: config.cfg [reader] @ readers = \"pdf-reader.v1\" [reader.extractor] @ extractors = \"pdfminer-extractor.v1\" [reader.transform] @ transforms = \"chain.v1\" [reader.transform.*.dates] @ transforms = \"dates.v1\" [reader.transform.*.telephone] @ transforms = \"telephone.v1\" [reader.transform.*.dimensions] @ transforms = \"dimensions.v1\" # The model has not been trained yet # We still reference it to make sure we use the same configuration [reader.classifier] @ classifiers = \"sklearn.v1\" path = \"classifier.joblib\" [reader.aggregator] @ aggregators = \"styled.v1\" Data preparation The reader object exposes a prepare_data method, which runs the pipeline until the classification phase, and returns the DataFrame as it would be seen by the classifier. Hence, we can use it to produce a training dataset for the classification step. It means that we can use the same configuration for preparing the training data for the classifier and for the full pipeline, guaranteeing that the data will be correctly pre-processed at runtime. # \u2191 Omitted code from the annotation recipe \u2191 import json import pandas as pd from edspdf import registry , Config from edspdf.reading import PdfReader from edspdf.classification.align import align_labels from pathlib import Path def prepare_dataset ( reader : PdfReader , directory : Path , ) -> pd . DataFrame : \"\"\" Read annotations from the dataset directory. Parameters ---------- directory : Path Dataset directory Returns ------- pd.DataFrame Pandas DataFrame containing the annotations. \"\"\" dfs = [] for path in directory . glob ( \"*.pdf\" ): meta = json . loads ( path . with_suffix ( \".json\" ) . read_text ()) del meta [ \"annotations\" ] df = reader ( path . read_bytes (), ** meta ) dfs . append ( df ) return pd . concat ( dfs ) config = Config () . from_disk ( \"config.cfg\" ) del config [ \"reader\" ][ \"classifier\" ] # (1) reader = registry . resolve ( config )[ \"reader\" ] path = Path ( \"dataset/train\" ) annotations = get_annotations ( path ) # (2) lines = prepare_dataset ( reader , path ) annotated = align_labels ( lines = lines , labels = annotations , threshold = 0.8 ) # (3) annotated . to_csv ( \"data.csv\" , index = False ) We remove the classifier from the pipeline definition since it is not defined at this point. See the PDF annotation recipe The object annotated now contains every text bloc that was covered by an annotated region, along with its label. Training the machine learning pipeline Now everything is ready to train a Scikit-Learn pipeline! Let's define a simple classifier: classifier.py from sklearn.compose import ColumnTransformer from sklearn.decomposition import TruncatedSVD from sklearn.ensemble import RandomForestClassifier from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler n_components = 20 max_features = 2000 seed = 0 text_vectorizer = Pipeline ( [ ( \"vect\" , CountVectorizer ( strip_accents = \"ascii\" , max_features = max_features )), ( \"tfidf\" , TfidfTransformer ()), ( \"reduction\" , TruncatedSVD ( n_components = n_components , random_state = seed )), ] ) classifier = Pipeline ( [ ( \"norm\" , StandardScaler ()), ( \"clf\" , RandomForestClassifier ( random_state = seed )), ] ) pipeline = Pipeline ( [ ( \"union\" , ColumnTransformer ( [ ( \"text\" , text_vectorizer , \"text\" ), ( \"others\" , \"passthrough\" , [ \"page\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"telephone\" , \"date\" , \"width\" , \"height\" , \"area\" , ], ), ] ), ), ( \"classifier\" , classifier ), ] ) And train it: import pandas as pd from joblib import dump from classifier import pipeline data = pd . read_csv ( \"data.csv\" ) X_train , Y_train = data . drop ( columns = [ \"label\" ]), data [ \"label\" ] pipeline . fit ( X_train , Y_train ) dump ( pipeline , \"classifier.joblib\" ) Using the full pipeline Now that the machine learning model is trained, we can use the full pipeline: import edspdf from pathlib import Path reader = edspdf . load ( \"config.cfg\" ) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n...","title":"A First Trained Pipeline"},{"location":"recipes/sklearn/#trained-pipeline-with-scikit-learn","text":"In this section, we'll see how we can train a machine-learning based classifier to get better performances. In this example, we will use a Scikit-Learn pipeline . Warning Scikit-Learn is ill-equipped to deal with text data. As such, it is not the best candidate to provide an effective classification method. However, it can still perform quite well and remains a good place to start tinkering with the inner workings of EDS-PDF.","title":"Trained Pipeline with Scikit-Learn"},{"location":"recipes/sklearn/#pdf-annotation","text":"See the PDF annotation recipe for one annotation methodology. For the rest of this recipe, we will consider that the dataset follows the same structure.","title":"PDF annotation"},{"location":"recipes/sklearn/#pipeline-definition","text":"Let's use the following pipeline: config.cfg [reader] @ readers = \"pdf-reader.v1\" [reader.extractor] @ extractors = \"pdfminer-extractor.v1\" [reader.transform] @ transforms = \"chain.v1\" [reader.transform.*.dates] @ transforms = \"dates.v1\" [reader.transform.*.telephone] @ transforms = \"telephone.v1\" [reader.transform.*.dimensions] @ transforms = \"dimensions.v1\" # The model has not been trained yet # We still reference it to make sure we use the same configuration [reader.classifier] @ classifiers = \"sklearn.v1\" path = \"classifier.joblib\" [reader.aggregator] @ aggregators = \"styled.v1\"","title":"Pipeline definition"},{"location":"recipes/sklearn/#data-preparation","text":"The reader object exposes a prepare_data method, which runs the pipeline until the classification phase, and returns the DataFrame as it would be seen by the classifier. Hence, we can use it to produce a training dataset for the classification step. It means that we can use the same configuration for preparing the training data for the classifier and for the full pipeline, guaranteeing that the data will be correctly pre-processed at runtime. # \u2191 Omitted code from the annotation recipe \u2191 import json import pandas as pd from edspdf import registry , Config from edspdf.reading import PdfReader from edspdf.classification.align import align_labels from pathlib import Path def prepare_dataset ( reader : PdfReader , directory : Path , ) -> pd . DataFrame : \"\"\" Read annotations from the dataset directory. Parameters ---------- directory : Path Dataset directory Returns ------- pd.DataFrame Pandas DataFrame containing the annotations. \"\"\" dfs = [] for path in directory . glob ( \"*.pdf\" ): meta = json . loads ( path . with_suffix ( \".json\" ) . read_text ()) del meta [ \"annotations\" ] df = reader ( path . read_bytes (), ** meta ) dfs . append ( df ) return pd . concat ( dfs ) config = Config () . from_disk ( \"config.cfg\" ) del config [ \"reader\" ][ \"classifier\" ] # (1) reader = registry . resolve ( config )[ \"reader\" ] path = Path ( \"dataset/train\" ) annotations = get_annotations ( path ) # (2) lines = prepare_dataset ( reader , path ) annotated = align_labels ( lines = lines , labels = annotations , threshold = 0.8 ) # (3) annotated . to_csv ( \"data.csv\" , index = False ) We remove the classifier from the pipeline definition since it is not defined at this point. See the PDF annotation recipe The object annotated now contains every text bloc that was covered by an annotated region, along with its label.","title":"Data preparation"},{"location":"recipes/sklearn/#training-the-machine-learning-pipeline","text":"Now everything is ready to train a Scikit-Learn pipeline! Let's define a simple classifier: classifier.py from sklearn.compose import ColumnTransformer from sklearn.decomposition import TruncatedSVD from sklearn.ensemble import RandomForestClassifier from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler n_components = 20 max_features = 2000 seed = 0 text_vectorizer = Pipeline ( [ ( \"vect\" , CountVectorizer ( strip_accents = \"ascii\" , max_features = max_features )), ( \"tfidf\" , TfidfTransformer ()), ( \"reduction\" , TruncatedSVD ( n_components = n_components , random_state = seed )), ] ) classifier = Pipeline ( [ ( \"norm\" , StandardScaler ()), ( \"clf\" , RandomForestClassifier ( random_state = seed )), ] ) pipeline = Pipeline ( [ ( \"union\" , ColumnTransformer ( [ ( \"text\" , text_vectorizer , \"text\" ), ( \"others\" , \"passthrough\" , [ \"page\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"telephone\" , \"date\" , \"width\" , \"height\" , \"area\" , ], ), ] ), ), ( \"classifier\" , classifier ), ] ) And train it: import pandas as pd from joblib import dump from classifier import pipeline data = pd . read_csv ( \"data.csv\" ) X_train , Y_train = data . drop ( columns = [ \"label\" ]), data [ \"label\" ] pipeline . fit ( X_train , Y_train ) dump ( pipeline , \"classifier.joblib\" )","title":"Training the machine learning pipeline"},{"location":"recipes/sklearn/#using-the-full-pipeline","text":"Now that the machine learning model is trained, we can use the full pipeline: import edspdf from pathlib import Path reader = edspdf . load ( \"config.cfg\" ) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () texts = reader ( pdf ) texts [ \"body\" ] # Out: Cher Pr ABC, Cher DEF,\\n...","title":"Using the full pipeline"},{"location":"reference/","text":"edspdf loading load ( path ) Load a complete pipeline. TODO: implement other ways to load a pipeline. PARAMETER DESCRIPTION path Path to the pipeline. TYPE: Path RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def load ( path : Path ) -> PdfReader : \"\"\" Load a complete pipeline. TODO: implement other ways to load a pipeline. Parameters ---------- path : Path Path to the pipeline. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_disk ( path ) return registry . resolve ( conf )[ \"reader\" ] from_str ( config ) Load a complete pipeline from a string config. PARAMETER DESCRIPTION config Configuration. TYPE: str RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def from_str ( config : str ) -> PdfReader : \"\"\" Load a complete pipeline from a string config. Parameters ---------- config : str Configuration. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_str ( config ) return registry . resolve ( conf )[ \"reader\" ] transforms base BaseTransform Bases: ABC Source code in edspdf/transforms/base.py 6 7 8 9 10 11 12 13 14 class BaseTransform ( ABC ): @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> pd . DataFrame : return self . transform ( lines ) transform ( lines ) abstractmethod Handles the transformation Source code in edspdf/transforms/base.py 7 8 9 10 11 @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\" readers reader PdfReader Source code in edspdf/readers/reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @registry . readers . register ( \"pdf-reader.v1\" ) class PdfReader : def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines def prepare_and_predict ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : lines = self . prepare_data ( pdf , ** context ) lines = self . predict ( lines ) return lines def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result __init__ ( extractor = None , classifier = None , aggregator = None , transform = None , meta_labels = dict ()) Reads a text-based PDF document, PARAMETER DESCRIPTION extractor Text bloc extractor. TYPE: BaseExtractor DEFAULT: None classifier Classifier model, to assign a section (eg body , header , etc). TYPE: BaseClassifier DEFAULT: None aggregator Aggregator model, to compile labelled text blocs together. TYPE: BaseAggregator DEFAULT: None transform Transformation to apply before classification. TYPE: BaseTransform , optional DEFAULT: None meta_labels Dictionary of hierarchical labels (eg table is probably within the body ). TYPE: Dict [ str , str ], optional DEFAULT: dict() Source code in edspdf/readers/reader.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels predict ( lines ) Predict the label of each text bloc. PARAMETER DESCRIPTION lines Text blocs to label. TYPE: pd . DataFrame RETURNS DESCRIPTION pd . DataFrame Labelled text blocs. Source code in edspdf/readers/reader.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines prepare_data ( pdf , ** context ) Prepare data before classification. Can also be used to generate the training dataset for the classifier. PARAMETER DESCRIPTION pdf PDF document, as bytes. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame Text blocs as a pandas DataFrame. Source code in edspdf/readers/reader.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines __call__ ( pdf , ** context ) Process the PDF document. PARAMETER DESCRIPTION pdf Byte representation of the PDF document. TYPE: bytes context : Any Any contextual information that is used by the classifier (eg document type or source). RETURNS DESCRIPTION Dict [ str , str ] Dictionary containing the aggregated text. Source code in edspdf/readers/reader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result classifiers align align_labels ( lines , labels , threshold = 0.0001 ) Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all PARAMETER DESCRIPTION lines DataFrame containing the lines TYPE: pd . DataFrame labels DataFrame containing the labels TYPE: pd . DataFrame threshold Threshold to use for discounting a label. Used if the labels DataFrame does not provide a threshold column, or to fill NaN values thereof. TYPE: float, default 1 DEFAULT: 0.0001 RETURNS DESCRIPTION pd . DataFrame A copy of the lines table, with the labels added. Source code in edspdf/classifiers/align.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def align_labels ( lines : pd . DataFrame , labels : pd . DataFrame , threshold : float = 0.0001 , ) -> pd . DataFrame : \"\"\" Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all Parameters ---------- lines : pd.DataFrame DataFrame containing the lines labels : pd.DataFrame DataFrame containing the labels threshold : float, default 1 Threshold to use for discounting a label. Used if the `labels` DataFrame does not provide a `threshold` column, or to fill `NaN` values thereof. Returns ------- pd.DataFrame A copy of the lines table, with the labels added. \"\"\" lines [ \"uid\" ] = range ( len ( lines )) df = lines [ sorted ({ \"uid\" , \"page\" , \"x0\" , \"y0\" , \"x1\" , \"y1\" } & set ( lines . columns )) ] . copy () labels = labels . copy () if \"threshold\" not in labels . columns : labels [ \"threshold\" ] = threshold labels . threshold = labels . threshold . fillna ( threshold ) df = df . merge ( labels , how = \"inner\" if set ( df . columns ) & set ( labels . columns ) else \"cross\" ) df [ \"dx\" ] = df [[ \"x1\" , \"X1\" ]] . min ( axis = 1 ) - df [[ \"x0\" , \"X0\" ]] . max ( axis = 1 ) df [ \"dy\" ] = df [[ \"y1\" , \"Y1\" ]] . min ( axis = 1 ) - df [[ \"y0\" , \"Y0\" ]] . max ( axis = 1 ) df [ \"overlap\" ] = ( df . dx > 0 ) * ( df . dy > 0 ) * df . dx * df . dy df [ \"area\" ] = ( df . x1 - df . x0 ) * ( df . y1 - df . y0 ) df [ \"ratio\" ] = df . overlap / df . area df [ \"area_mask\" ] = ( df . X1 - df . X0 ) * ( df . Y1 - df . Y0 ) df [ \"ratio_mask\" ] = df . overlap / df . area_mask df [ \"thresholded\" ] = df . ratio >= df . threshold df = df . sort_values ([ \"thresholded\" , \"ratio_mask\" ], ascending = False ) df = df . groupby ([ \"uid\" ], as_index = False ) . first () df = df . sort_values ( \"uid\" ) . reset_index ( drop = True ) df . label = df . label . where ( df . thresholded ) df = lines . merge ( df [[ \"uid\" , \"label\" ]], on = \"uid\" ) . drop ( columns = [ \"uid\" ]) lines . drop ( columns = \"uid\" , inplace = True ) return df base BaseClassifier Bases: ABC Source code in edspdf/classifiers/base.py 7 8 9 10 11 12 13 14 15 class BaseClassifier ( ABC ): @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> List [ str ]: return self . predict ( lines ) predict ( lines ) abstractmethod Handles the classification. Source code in edspdf/classifiers/base.py 8 9 10 11 12 @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" dummy DummyClassifier Bases: BaseClassifier \"Dummy\" classifier, for testing purposes. Classifies every line to body . Source code in edspdf/classifiers/dummy.py 10 11 12 13 14 15 16 17 @registry . classifiers . register ( \"dummy.v1\" ) class DummyClassifier ( BaseClassifier ): \"\"\" \"Dummy\" classifier, for testing purposes. Classifies every line to ``body``. \"\"\" def predict ( self , lines : pd . DataFrame ) -> List [ str ]: return [ \"body\" ] * len ( lines ) random RandomClassifier Bases: BaseClassifier Random classifier, for chaos purposes. Classifies each line to a random element. Source code in edspdf/classifiers/random.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @registry . classifiers . register ( \"random.v1\" ) class RandomClassifier ( BaseClassifier ): \"\"\" Random classifier, for chaos purposes. Classifies each line to a random element. \"\"\" def __init__ ( self , classes : Union [ List [ str ], Dict [ str , float ]], seed : Optional [ int ] = 0 , ) -> None : if isinstance ( classes , list ): classes = { c : 1 for c in classes } self . classes = { c : w / sum ( classes . values ()) for c , w in classes . items ()} self . rgn = np . random . default_rng ( seed = seed ) def predict ( self , lines : pd . DataFrame ) -> List [ str ]: choices = self . rgn . choice ( list ( self . classes . keys ()), p = list ( self . classes . values ()), size = len ( lines ), ) return list ( choices ) mask MaskClassifier Bases: BaseClassifier Mask classifier, that reproduces the PdfBox behaviour. Source code in edspdf/classifiers/mask.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class MaskClassifier ( BaseClassifier ): \"\"\" Mask classifier, that reproduces the PdfBox behaviour. \"\"\" def __init__ ( self , * ms : Mask , ) -> None : masks = list ( ms ) masks . append ( Mask ( label = \"pollution\" )) self . comparison = pd . DataFrame . from_records ([ mask . dict () for mask in masks ]) def predict ( self , lines : pd . DataFrame ) -> pd . Series : df = align_labels ( lines , self . comparison ) return df . label aggregators styled StyledAggregator Bases: SimpleAggregator Aggregator that returns text and styles. Source code in edspdf/aggregators/styled.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @registry . aggregators . register ( \"styled.v1\" ) class StyledAggregator ( SimpleAggregator ): \"\"\" Aggregator that returns text and styles. \"\"\" def aggregate ( self , lines : pd . DataFrame ) -> Tuple [ Dict [ str , str ], Dict [ str , List [ Dict ]]]: lines = lines . sort_values ([ \"page\" , \"y1\" , \"x0\" ]) lines [ \"line_id\" ] = range ( len ( lines )) styles = lines [[ \"line_id\" , \"styles\" ]] . explode ( \"styles\" ) . dropna () . reset_index () styles = styles [[ \"line_id\" ]] . join ( pd . json_normalize ( styles . styles )) lines = prepare_newlines ( lines , nl_threshold = self . nl_threshold , np_threshold = self . np_threshold , ) lines [ \"offset\" ] = lines [ \"text_with_newline\" ] . str . len () lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"cumsum\" ) lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"shift\" ) lines [ \"offset\" ] = lines [ \"offset\" ] . fillna ( 0 ) . astype ( int ) styles = styles . merge ( lines [[ \"line_id\" , \"offset\" , \"label\" ]], on = \"line_id\" ) styles [ \"start\" ] += styles . offset styles [ \"end\" ] += styles . offset df = lines . groupby ([ \"label\" ]) . agg ( text = ( \"text_with_newline\" , \"sum\" )) text = df . text . to_dict () style = { label : styles . query ( \"label == @label\" ) . drop ( columns = [ \"line_id\" , \"offset\" , \"label\" ]) . to_dict ( orient = \"records\" ) for label in text . keys () } return text , style base BaseAggregator Bases: ABC Source code in edspdf/aggregators/base.py 7 8 9 10 11 12 13 14 15 16 17 class BaseAggregator ( ABC ): @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\" def __call__ ( self , lines : pd . DataFrame , copy : bool = False ) -> Dict [ str , str ]: if copy : lines = lines . copy () return self . aggregate ( lines ) aggregate ( lines ) abstractmethod Handles the text aggregation Source code in edspdf/aggregators/base.py 8 9 10 11 12 @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\" extractors pdfminer PdfMinerExtractor Bases: BaseExtractor Extractor object. Given a PDF byte stream, produces a list of blocs. PARAMETER DESCRIPTION line_overlap See PDFMiner documentation TYPE: float DEFAULT: 0.5 char_margin See PDFMiner documentation TYPE: float DEFAULT: 2.0 line_margin See PDFMiner documentation TYPE: float DEFAULT: 0.5 word_margin See PDFMiner documentation TYPE: float DEFAULT: 0.1 boxes_flow See PDFMiner documentation TYPE: Optional [ float ] DEFAULT: 0.5 detect_vertical See PDFMiner documentation TYPE: bool DEFAULT: False all_texts See PDFMiner documentation TYPE: bool DEFAULT: False Source code in edspdf/extractors/pdfminer.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @registry . extractors . register ( \"pdfminer.v1\" ) class PdfMinerExtractor ( BaseExtractor ): \"\"\" Extractor object. Given a PDF byte stream, produces a list of blocs. Parameters ---------- line_overlap : float See PDFMiner documentation char_margin : float See PDFMiner documentation line_margin : float See PDFMiner documentation word_margin : float See PDFMiner documentation boxes_flow : Optional[float] See PDFMiner documentation detect_vertical : bool See PDFMiner documentation all_texts : bool See PDFMiner documentation \"\"\" def __init__ ( self , line_overlap : float = 0.5 , char_margin : float = 2.0 , line_margin : float = 0.5 , word_margin : float = 0.1 , boxes_flow : Optional [ float ] = 0.5 , detect_vertical : bool = False , all_texts : bool = False , ): self . laparams = LAParams ( line_overlap = line_overlap , char_margin = char_margin , line_margin = line_margin , word_margin = word_margin , boxes_flow = boxes_flow , detect_vertical = detect_vertical , all_texts = all_texts , ) def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines generate_lines ( pdf ) Generates dataframe from all blocs in the PDF. Arguments pdf: Byte stream representing the PDF. RETURNS DESCRIPTION pd . DataFrame DataFrame representing the blocs. Source code in edspdf/extractors/pdfminer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df extract ( pdf ) Process a single PDF document. PARAMETER DESCRIPTION pdf Raw byte representation of the PDF document. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame DataFrame containing one row for each line extracted using PDFMiner. Source code in edspdf/extractors/pdfminer.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines base BaseExtractor Bases: ABC Source code in edspdf/extractors/base.py 6 7 8 9 10 11 12 13 14 class BaseExtractor ( ABC ): @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" def __call__ ( self , pdf : bytes ) -> pd . DataFrame : return self . extract ( pdf ) extract ( pdf ) abstractmethod Handles the extraction Source code in edspdf/extractors/base.py 7 8 9 10 11 @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" functional get_blocs ( layout ) Extract text blocs from a PDFMiner layout generator. Arguments layout: PDFMiner layout generator. YIELDS DESCRIPTION bloc Text bloc TYPE: Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]] Source code in edspdf/extractors/functional.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_blocs ( layout : Iterator [ LTPage ], ) -> Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]]: \"\"\" Extract text blocs from a PDFMiner layout generator. Arguments --------- layout: PDFMiner layout generator. Yields ------ bloc : Text bloc \"\"\" for i , page in enumerate ( layout ): width = page . width height = page . height for bloc in page : if isinstance ( bloc , LTTextBoxHorizontal ): yield bloc , i , width , height get_lines ( layout ) Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. PARAMETER DESCRIPTION layout PDFMiner layout object. TYPE: Iterator [ LTPage ] YIELDS DESCRIPTION Iterator [ Line ] Single line object. Source code in edspdf/extractors/functional.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_lines ( layout : Iterator [ LTPage ]) -> Iterator [ Line ]: \"\"\" Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. Parameters ---------- layout : Iterator[LTPage] PDFMiner layout object. Yields ------- Iterator[Line] Single line object. \"\"\" for b , ( bloc , p , w , h ) in enumerate ( get_blocs ( layout )): for line in bloc : text , styles = extract_style ( line , width = w , height = h ) yield Line ( page = p , bloc = b , x0 = line . x0 / w , x1 = line . x1 / w , y0 = 1 - line . y1 / h , y1 = 1 - line . y0 / h , page_width = w , page_height = h , text = text , styles = styles , ) remove_outside_lines ( lines , strict_mode = False ) Filter out lines that are outside the canvas. PARAMETER DESCRIPTION lines Dataframe of extracted lines TYPE: pd . DataFrame strict_mode Whether to remove the line if any part of it is outside the canvas, by default False TYPE: bool , optional DEFAULT: False RETURNS DESCRIPTION pd . DataFrame Filtered lines. Source code in edspdf/extractors/functional.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def remove_outside_lines ( lines : pd . DataFrame , strict_mode : bool = False , ) -> pd . DataFrame : \"\"\" Filter out lines that are outside the canvas. Parameters ---------- lines : pd.DataFrame Dataframe of extracted lines strict_mode : bool, optional Whether to remove the line if any part of it is outside the canvas, by default False Returns ------- pd.DataFrame Filtered lines. \"\"\" if strict_mode : lower = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) >= 0 upper = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) <= 1 lines = lines [ lower & upper ] else : below = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) < 0 above = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) > 0 lines = lines [ ~ ( below | above )] return lines style models BaseStyle Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float Style Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st from_fontname ( fontname , size , upright , x0 , x1 , y0 , y1 ) classmethod Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s __eq__ ( other ) Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o StyledText Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"`edspdf`"},{"location":"reference/#edspdf","text":"","title":"edspdf"},{"location":"reference/#edspdf.loading","text":"","title":"loading"},{"location":"reference/#edspdf.loading.load","text":"Load a complete pipeline. TODO: implement other ways to load a pipeline. PARAMETER DESCRIPTION path Path to the pipeline. TYPE: Path RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def load ( path : Path ) -> PdfReader : \"\"\" Load a complete pipeline. TODO: implement other ways to load a pipeline. Parameters ---------- path : Path Path to the pipeline. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_disk ( path ) return registry . resolve ( conf )[ \"reader\" ]","title":"load()"},{"location":"reference/#edspdf.loading.from_str","text":"Load a complete pipeline from a string config. PARAMETER DESCRIPTION config Configuration. TYPE: str RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def from_str ( config : str ) -> PdfReader : \"\"\" Load a complete pipeline from a string config. Parameters ---------- config : str Configuration. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_str ( config ) return registry . resolve ( conf )[ \"reader\" ]","title":"from_str()"},{"location":"reference/#edspdf.transforms","text":"","title":"transforms"},{"location":"reference/#edspdf.transforms.base","text":"","title":"base"},{"location":"reference/#edspdf.transforms.base.BaseTransform","text":"Bases: ABC Source code in edspdf/transforms/base.py 6 7 8 9 10 11 12 13 14 class BaseTransform ( ABC ): @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> pd . DataFrame : return self . transform ( lines )","title":"BaseTransform"},{"location":"reference/#edspdf.transforms.base.BaseTransform.transform","text":"Handles the transformation Source code in edspdf/transforms/base.py 7 8 9 10 11 @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\"","title":"transform()"},{"location":"reference/#edspdf.readers","text":"","title":"readers"},{"location":"reference/#edspdf.readers.reader","text":"","title":"reader"},{"location":"reference/#edspdf.readers.reader.PdfReader","text":"Source code in edspdf/readers/reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @registry . readers . register ( \"pdf-reader.v1\" ) class PdfReader : def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines def prepare_and_predict ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : lines = self . prepare_data ( pdf , ** context ) lines = self . predict ( lines ) return lines def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"PdfReader"},{"location":"reference/#edspdf.readers.reader.PdfReader.__init__","text":"Reads a text-based PDF document, PARAMETER DESCRIPTION extractor Text bloc extractor. TYPE: BaseExtractor DEFAULT: None classifier Classifier model, to assign a section (eg body , header , etc). TYPE: BaseClassifier DEFAULT: None aggregator Aggregator model, to compile labelled text blocs together. TYPE: BaseAggregator DEFAULT: None transform Transformation to apply before classification. TYPE: BaseTransform , optional DEFAULT: None meta_labels Dictionary of hierarchical labels (eg table is probably within the body ). TYPE: Dict [ str , str ], optional DEFAULT: dict() Source code in edspdf/readers/reader.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels","title":"__init__()"},{"location":"reference/#edspdf.readers.reader.PdfReader.predict","text":"Predict the label of each text bloc. PARAMETER DESCRIPTION lines Text blocs to label. TYPE: pd . DataFrame RETURNS DESCRIPTION pd . DataFrame Labelled text blocs. Source code in edspdf/readers/reader.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines","title":"predict()"},{"location":"reference/#edspdf.readers.reader.PdfReader.prepare_data","text":"Prepare data before classification. Can also be used to generate the training dataset for the classifier. PARAMETER DESCRIPTION pdf PDF document, as bytes. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame Text blocs as a pandas DataFrame. Source code in edspdf/readers/reader.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines","title":"prepare_data()"},{"location":"reference/#edspdf.readers.reader.PdfReader.__call__","text":"Process the PDF document. PARAMETER DESCRIPTION pdf Byte representation of the PDF document. TYPE: bytes context : Any Any contextual information that is used by the classifier (eg document type or source). RETURNS DESCRIPTION Dict [ str , str ] Dictionary containing the aggregated text. Source code in edspdf/readers/reader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"__call__()"},{"location":"reference/#edspdf.classifiers","text":"","title":"classifiers"},{"location":"reference/#edspdf.classifiers.align","text":"","title":"align"},{"location":"reference/#edspdf.classifiers.align.align_labels","text":"Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all PARAMETER DESCRIPTION lines DataFrame containing the lines TYPE: pd . DataFrame labels DataFrame containing the labels TYPE: pd . DataFrame threshold Threshold to use for discounting a label. Used if the labels DataFrame does not provide a threshold column, or to fill NaN values thereof. TYPE: float, default 1 DEFAULT: 0.0001 RETURNS DESCRIPTION pd . DataFrame A copy of the lines table, with the labels added. Source code in edspdf/classifiers/align.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def align_labels ( lines : pd . DataFrame , labels : pd . DataFrame , threshold : float = 0.0001 , ) -> pd . DataFrame : \"\"\" Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all Parameters ---------- lines : pd.DataFrame DataFrame containing the lines labels : pd.DataFrame DataFrame containing the labels threshold : float, default 1 Threshold to use for discounting a label. Used if the `labels` DataFrame does not provide a `threshold` column, or to fill `NaN` values thereof. Returns ------- pd.DataFrame A copy of the lines table, with the labels added. \"\"\" lines [ \"uid\" ] = range ( len ( lines )) df = lines [ sorted ({ \"uid\" , \"page\" , \"x0\" , \"y0\" , \"x1\" , \"y1\" } & set ( lines . columns )) ] . copy () labels = labels . copy () if \"threshold\" not in labels . columns : labels [ \"threshold\" ] = threshold labels . threshold = labels . threshold . fillna ( threshold ) df = df . merge ( labels , how = \"inner\" if set ( df . columns ) & set ( labels . columns ) else \"cross\" ) df [ \"dx\" ] = df [[ \"x1\" , \"X1\" ]] . min ( axis = 1 ) - df [[ \"x0\" , \"X0\" ]] . max ( axis = 1 ) df [ \"dy\" ] = df [[ \"y1\" , \"Y1\" ]] . min ( axis = 1 ) - df [[ \"y0\" , \"Y0\" ]] . max ( axis = 1 ) df [ \"overlap\" ] = ( df . dx > 0 ) * ( df . dy > 0 ) * df . dx * df . dy df [ \"area\" ] = ( df . x1 - df . x0 ) * ( df . y1 - df . y0 ) df [ \"ratio\" ] = df . overlap / df . area df [ \"area_mask\" ] = ( df . X1 - df . X0 ) * ( df . Y1 - df . Y0 ) df [ \"ratio_mask\" ] = df . overlap / df . area_mask df [ \"thresholded\" ] = df . ratio >= df . threshold df = df . sort_values ([ \"thresholded\" , \"ratio_mask\" ], ascending = False ) df = df . groupby ([ \"uid\" ], as_index = False ) . first () df = df . sort_values ( \"uid\" ) . reset_index ( drop = True ) df . label = df . label . where ( df . thresholded ) df = lines . merge ( df [[ \"uid\" , \"label\" ]], on = \"uid\" ) . drop ( columns = [ \"uid\" ]) lines . drop ( columns = \"uid\" , inplace = True ) return df","title":"align_labels()"},{"location":"reference/#edspdf.classifiers.base","text":"","title":"base"},{"location":"reference/#edspdf.classifiers.base.BaseClassifier","text":"Bases: ABC Source code in edspdf/classifiers/base.py 7 8 9 10 11 12 13 14 15 class BaseClassifier ( ABC ): @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> List [ str ]: return self . predict ( lines )","title":"BaseClassifier"},{"location":"reference/#edspdf.classifiers.base.BaseClassifier.predict","text":"Handles the classification. Source code in edspdf/classifiers/base.py 8 9 10 11 12 @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\"","title":"predict()"},{"location":"reference/#edspdf.classifiers.dummy","text":"","title":"dummy"},{"location":"reference/#edspdf.classifiers.dummy.DummyClassifier","text":"Bases: BaseClassifier \"Dummy\" classifier, for testing purposes. Classifies every line to body . Source code in edspdf/classifiers/dummy.py 10 11 12 13 14 15 16 17 @registry . classifiers . register ( \"dummy.v1\" ) class DummyClassifier ( BaseClassifier ): \"\"\" \"Dummy\" classifier, for testing purposes. Classifies every line to ``body``. \"\"\" def predict ( self , lines : pd . DataFrame ) -> List [ str ]: return [ \"body\" ] * len ( lines )","title":"DummyClassifier"},{"location":"reference/#edspdf.classifiers.random","text":"","title":"random"},{"location":"reference/#edspdf.classifiers.random.RandomClassifier","text":"Bases: BaseClassifier Random classifier, for chaos purposes. Classifies each line to a random element. Source code in edspdf/classifiers/random.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @registry . classifiers . register ( \"random.v1\" ) class RandomClassifier ( BaseClassifier ): \"\"\" Random classifier, for chaos purposes. Classifies each line to a random element. \"\"\" def __init__ ( self , classes : Union [ List [ str ], Dict [ str , float ]], seed : Optional [ int ] = 0 , ) -> None : if isinstance ( classes , list ): classes = { c : 1 for c in classes } self . classes = { c : w / sum ( classes . values ()) for c , w in classes . items ()} self . rgn = np . random . default_rng ( seed = seed ) def predict ( self , lines : pd . DataFrame ) -> List [ str ]: choices = self . rgn . choice ( list ( self . classes . keys ()), p = list ( self . classes . values ()), size = len ( lines ), ) return list ( choices )","title":"RandomClassifier"},{"location":"reference/#edspdf.classifiers.mask","text":"","title":"mask"},{"location":"reference/#edspdf.classifiers.mask.MaskClassifier","text":"Bases: BaseClassifier Mask classifier, that reproduces the PdfBox behaviour. Source code in edspdf/classifiers/mask.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class MaskClassifier ( BaseClassifier ): \"\"\" Mask classifier, that reproduces the PdfBox behaviour. \"\"\" def __init__ ( self , * ms : Mask , ) -> None : masks = list ( ms ) masks . append ( Mask ( label = \"pollution\" )) self . comparison = pd . DataFrame . from_records ([ mask . dict () for mask in masks ]) def predict ( self , lines : pd . DataFrame ) -> pd . Series : df = align_labels ( lines , self . comparison ) return df . label","title":"MaskClassifier"},{"location":"reference/#edspdf.aggregators","text":"","title":"aggregators"},{"location":"reference/#edspdf.aggregators.styled","text":"","title":"styled"},{"location":"reference/#edspdf.aggregators.styled.StyledAggregator","text":"Bases: SimpleAggregator Aggregator that returns text and styles. Source code in edspdf/aggregators/styled.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @registry . aggregators . register ( \"styled.v1\" ) class StyledAggregator ( SimpleAggregator ): \"\"\" Aggregator that returns text and styles. \"\"\" def aggregate ( self , lines : pd . DataFrame ) -> Tuple [ Dict [ str , str ], Dict [ str , List [ Dict ]]]: lines = lines . sort_values ([ \"page\" , \"y1\" , \"x0\" ]) lines [ \"line_id\" ] = range ( len ( lines )) styles = lines [[ \"line_id\" , \"styles\" ]] . explode ( \"styles\" ) . dropna () . reset_index () styles = styles [[ \"line_id\" ]] . join ( pd . json_normalize ( styles . styles )) lines = prepare_newlines ( lines , nl_threshold = self . nl_threshold , np_threshold = self . np_threshold , ) lines [ \"offset\" ] = lines [ \"text_with_newline\" ] . str . len () lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"cumsum\" ) lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"shift\" ) lines [ \"offset\" ] = lines [ \"offset\" ] . fillna ( 0 ) . astype ( int ) styles = styles . merge ( lines [[ \"line_id\" , \"offset\" , \"label\" ]], on = \"line_id\" ) styles [ \"start\" ] += styles . offset styles [ \"end\" ] += styles . offset df = lines . groupby ([ \"label\" ]) . agg ( text = ( \"text_with_newline\" , \"sum\" )) text = df . text . to_dict () style = { label : styles . query ( \"label == @label\" ) . drop ( columns = [ \"line_id\" , \"offset\" , \"label\" ]) . to_dict ( orient = \"records\" ) for label in text . keys () } return text , style","title":"StyledAggregator"},{"location":"reference/#edspdf.aggregators.base","text":"","title":"base"},{"location":"reference/#edspdf.aggregators.base.BaseAggregator","text":"Bases: ABC Source code in edspdf/aggregators/base.py 7 8 9 10 11 12 13 14 15 16 17 class BaseAggregator ( ABC ): @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\" def __call__ ( self , lines : pd . DataFrame , copy : bool = False ) -> Dict [ str , str ]: if copy : lines = lines . copy () return self . aggregate ( lines )","title":"BaseAggregator"},{"location":"reference/#edspdf.aggregators.base.BaseAggregator.aggregate","text":"Handles the text aggregation Source code in edspdf/aggregators/base.py 8 9 10 11 12 @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\"","title":"aggregate()"},{"location":"reference/#edspdf.extractors","text":"","title":"extractors"},{"location":"reference/#edspdf.extractors.pdfminer","text":"","title":"pdfminer"},{"location":"reference/#edspdf.extractors.pdfminer.PdfMinerExtractor","text":"Bases: BaseExtractor Extractor object. Given a PDF byte stream, produces a list of blocs. PARAMETER DESCRIPTION line_overlap See PDFMiner documentation TYPE: float DEFAULT: 0.5 char_margin See PDFMiner documentation TYPE: float DEFAULT: 2.0 line_margin See PDFMiner documentation TYPE: float DEFAULT: 0.5 word_margin See PDFMiner documentation TYPE: float DEFAULT: 0.1 boxes_flow See PDFMiner documentation TYPE: Optional [ float ] DEFAULT: 0.5 detect_vertical See PDFMiner documentation TYPE: bool DEFAULT: False all_texts See PDFMiner documentation TYPE: bool DEFAULT: False Source code in edspdf/extractors/pdfminer.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @registry . extractors . register ( \"pdfminer.v1\" ) class PdfMinerExtractor ( BaseExtractor ): \"\"\" Extractor object. Given a PDF byte stream, produces a list of blocs. Parameters ---------- line_overlap : float See PDFMiner documentation char_margin : float See PDFMiner documentation line_margin : float See PDFMiner documentation word_margin : float See PDFMiner documentation boxes_flow : Optional[float] See PDFMiner documentation detect_vertical : bool See PDFMiner documentation all_texts : bool See PDFMiner documentation \"\"\" def __init__ ( self , line_overlap : float = 0.5 , char_margin : float = 2.0 , line_margin : float = 0.5 , word_margin : float = 0.1 , boxes_flow : Optional [ float ] = 0.5 , detect_vertical : bool = False , all_texts : bool = False , ): self . laparams = LAParams ( line_overlap = line_overlap , char_margin = char_margin , line_margin = line_margin , word_margin = word_margin , boxes_flow = boxes_flow , detect_vertical = detect_vertical , all_texts = all_texts , ) def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines","title":"PdfMinerExtractor"},{"location":"reference/#edspdf.extractors.pdfminer.PdfMinerExtractor.generate_lines","text":"Generates dataframe from all blocs in the PDF.","title":"generate_lines()"},{"location":"reference/#edspdf.extractors.pdfminer.PdfMinerExtractor.generate_lines--arguments","text":"pdf: Byte stream representing the PDF. RETURNS DESCRIPTION pd . DataFrame DataFrame representing the blocs. Source code in edspdf/extractors/pdfminer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df","title":"Arguments"},{"location":"reference/#edspdf.extractors.pdfminer.PdfMinerExtractor.extract","text":"Process a single PDF document. PARAMETER DESCRIPTION pdf Raw byte representation of the PDF document. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame DataFrame containing one row for each line extracted using PDFMiner. Source code in edspdf/extractors/pdfminer.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines","title":"extract()"},{"location":"reference/#edspdf.extractors.base","text":"","title":"base"},{"location":"reference/#edspdf.extractors.base.BaseExtractor","text":"Bases: ABC Source code in edspdf/extractors/base.py 6 7 8 9 10 11 12 13 14 class BaseExtractor ( ABC ): @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" def __call__ ( self , pdf : bytes ) -> pd . DataFrame : return self . extract ( pdf )","title":"BaseExtractor"},{"location":"reference/#edspdf.extractors.base.BaseExtractor.extract","text":"Handles the extraction Source code in edspdf/extractors/base.py 7 8 9 10 11 @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\"","title":"extract()"},{"location":"reference/#edspdf.extractors.functional","text":"","title":"functional"},{"location":"reference/#edspdf.extractors.functional.get_blocs","text":"Extract text blocs from a PDFMiner layout generator.","title":"get_blocs()"},{"location":"reference/#edspdf.extractors.functional.get_blocs--arguments","text":"layout: PDFMiner layout generator. YIELDS DESCRIPTION bloc Text bloc TYPE: Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]] Source code in edspdf/extractors/functional.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_blocs ( layout : Iterator [ LTPage ], ) -> Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]]: \"\"\" Extract text blocs from a PDFMiner layout generator. Arguments --------- layout: PDFMiner layout generator. Yields ------ bloc : Text bloc \"\"\" for i , page in enumerate ( layout ): width = page . width height = page . height for bloc in page : if isinstance ( bloc , LTTextBoxHorizontal ): yield bloc , i , width , height","title":"Arguments"},{"location":"reference/#edspdf.extractors.functional.get_lines","text":"Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. PARAMETER DESCRIPTION layout PDFMiner layout object. TYPE: Iterator [ LTPage ] YIELDS DESCRIPTION Iterator [ Line ] Single line object. Source code in edspdf/extractors/functional.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_lines ( layout : Iterator [ LTPage ]) -> Iterator [ Line ]: \"\"\" Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. Parameters ---------- layout : Iterator[LTPage] PDFMiner layout object. Yields ------- Iterator[Line] Single line object. \"\"\" for b , ( bloc , p , w , h ) in enumerate ( get_blocs ( layout )): for line in bloc : text , styles = extract_style ( line , width = w , height = h ) yield Line ( page = p , bloc = b , x0 = line . x0 / w , x1 = line . x1 / w , y0 = 1 - line . y1 / h , y1 = 1 - line . y0 / h , page_width = w , page_height = h , text = text , styles = styles , )","title":"get_lines()"},{"location":"reference/#edspdf.extractors.functional.remove_outside_lines","text":"Filter out lines that are outside the canvas. PARAMETER DESCRIPTION lines Dataframe of extracted lines TYPE: pd . DataFrame strict_mode Whether to remove the line if any part of it is outside the canvas, by default False TYPE: bool , optional DEFAULT: False RETURNS DESCRIPTION pd . DataFrame Filtered lines. Source code in edspdf/extractors/functional.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def remove_outside_lines ( lines : pd . DataFrame , strict_mode : bool = False , ) -> pd . DataFrame : \"\"\" Filter out lines that are outside the canvas. Parameters ---------- lines : pd.DataFrame Dataframe of extracted lines strict_mode : bool, optional Whether to remove the line if any part of it is outside the canvas, by default False Returns ------- pd.DataFrame Filtered lines. \"\"\" if strict_mode : lower = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) >= 0 upper = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) <= 1 lines = lines [ lower & upper ] else : below = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) < 0 above = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) > 0 lines = lines [ ~ ( below | above )] return lines","title":"remove_outside_lines()"},{"location":"reference/#edspdf.extractors.style","text":"","title":"style"},{"location":"reference/#edspdf.extractors.style.models","text":"","title":"models"},{"location":"reference/#edspdf.extractors.style.models.BaseStyle","text":"Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float","title":"BaseStyle"},{"location":"reference/#edspdf.extractors.style.models.Style","text":"Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st","title":"Style"},{"location":"reference/#edspdf.extractors.style.models.Style.from_fontname","text":"Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s","title":"from_fontname()"},{"location":"reference/#edspdf.extractors.style.models.Style.__eq__","text":"Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o","title":"__eq__()"},{"location":"reference/#edspdf.extractors.style.models.StyledText","text":"Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"StyledText"},{"location":"reference/SUMMARY/","text":"edspdf aggregators base functional simple styled classifiers align base dummy mask random sklearn extractors base functional models pdfminer style models style loading misc package readers reader reg transforms base transforms visualization annotations merge","title":"SUMMARY"},{"location":"reference/loading/","text":"edspdf.loading load ( path ) Load a complete pipeline. TODO: implement other ways to load a pipeline. PARAMETER DESCRIPTION path Path to the pipeline. TYPE: Path RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def load ( path : Path ) -> PdfReader : \"\"\" Load a complete pipeline. TODO: implement other ways to load a pipeline. Parameters ---------- path : Path Path to the pipeline. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_disk ( path ) return registry . resolve ( conf )[ \"reader\" ] from_str ( config ) Load a complete pipeline from a string config. PARAMETER DESCRIPTION config Configuration. TYPE: str RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def from_str ( config : str ) -> PdfReader : \"\"\" Load a complete pipeline from a string config. Parameters ---------- config : str Configuration. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_str ( config ) return registry . resolve ( conf )[ \"reader\" ]","title":"loading"},{"location":"reference/loading/#edspdfloading","text":"","title":"edspdf.loading"},{"location":"reference/loading/#edspdf.loading.load","text":"Load a complete pipeline. TODO: implement other ways to load a pipeline. PARAMETER DESCRIPTION path Path to the pipeline. TYPE: Path RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def load ( path : Path ) -> PdfReader : \"\"\" Load a complete pipeline. TODO: implement other ways to load a pipeline. Parameters ---------- path : Path Path to the pipeline. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_disk ( path ) return registry . resolve ( conf )[ \"reader\" ]","title":"load()"},{"location":"reference/loading/#edspdf.loading.from_str","text":"Load a complete pipeline from a string config. PARAMETER DESCRIPTION config Configuration. TYPE: str RETURNS DESCRIPTION PdfReader A PdfReader object. Source code in edspdf/loading.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def from_str ( config : str ) -> PdfReader : \"\"\" Load a complete pipeline from a string config. Parameters ---------- config : str Configuration. Returns ------- PdfReader A PdfReader object. \"\"\" conf = Config () . from_str ( config ) return registry . resolve ( conf )[ \"reader\" ]","title":"from_str()"},{"location":"reference/reg/","text":"edspdf.reg","title":"reg"},{"location":"reference/reg/#edspdfreg","text":"","title":"edspdf.reg"},{"location":"reference/aggregators/","text":"edspdf.aggregators styled StyledAggregator Bases: SimpleAggregator Aggregator that returns text and styles. Source code in edspdf/aggregators/styled.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @registry . aggregators . register ( \"styled.v1\" ) class StyledAggregator ( SimpleAggregator ): \"\"\" Aggregator that returns text and styles. \"\"\" def aggregate ( self , lines : pd . DataFrame ) -> Tuple [ Dict [ str , str ], Dict [ str , List [ Dict ]]]: lines = lines . sort_values ([ \"page\" , \"y1\" , \"x0\" ]) lines [ \"line_id\" ] = range ( len ( lines )) styles = lines [[ \"line_id\" , \"styles\" ]] . explode ( \"styles\" ) . dropna () . reset_index () styles = styles [[ \"line_id\" ]] . join ( pd . json_normalize ( styles . styles )) lines = prepare_newlines ( lines , nl_threshold = self . nl_threshold , np_threshold = self . np_threshold , ) lines [ \"offset\" ] = lines [ \"text_with_newline\" ] . str . len () lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"cumsum\" ) lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"shift\" ) lines [ \"offset\" ] = lines [ \"offset\" ] . fillna ( 0 ) . astype ( int ) styles = styles . merge ( lines [[ \"line_id\" , \"offset\" , \"label\" ]], on = \"line_id\" ) styles [ \"start\" ] += styles . offset styles [ \"end\" ] += styles . offset df = lines . groupby ([ \"label\" ]) . agg ( text = ( \"text_with_newline\" , \"sum\" )) text = df . text . to_dict () style = { label : styles . query ( \"label == @label\" ) . drop ( columns = [ \"line_id\" , \"offset\" , \"label\" ]) . to_dict ( orient = \"records\" ) for label in text . keys () } return text , style base BaseAggregator Bases: ABC Source code in edspdf/aggregators/base.py 7 8 9 10 11 12 13 14 15 16 17 class BaseAggregator ( ABC ): @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\" def __call__ ( self , lines : pd . DataFrame , copy : bool = False ) -> Dict [ str , str ]: if copy : lines = lines . copy () return self . aggregate ( lines ) aggregate ( lines ) abstractmethod Handles the text aggregation Source code in edspdf/aggregators/base.py 8 9 10 11 12 @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\"","title":"`edspdf.aggregators`"},{"location":"reference/aggregators/#edspdfaggregators","text":"","title":"edspdf.aggregators"},{"location":"reference/aggregators/#edspdf.aggregators.styled","text":"","title":"styled"},{"location":"reference/aggregators/#edspdf.aggregators.styled.StyledAggregator","text":"Bases: SimpleAggregator Aggregator that returns text and styles. Source code in edspdf/aggregators/styled.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @registry . aggregators . register ( \"styled.v1\" ) class StyledAggregator ( SimpleAggregator ): \"\"\" Aggregator that returns text and styles. \"\"\" def aggregate ( self , lines : pd . DataFrame ) -> Tuple [ Dict [ str , str ], Dict [ str , List [ Dict ]]]: lines = lines . sort_values ([ \"page\" , \"y1\" , \"x0\" ]) lines [ \"line_id\" ] = range ( len ( lines )) styles = lines [[ \"line_id\" , \"styles\" ]] . explode ( \"styles\" ) . dropna () . reset_index () styles = styles [[ \"line_id\" ]] . join ( pd . json_normalize ( styles . styles )) lines = prepare_newlines ( lines , nl_threshold = self . nl_threshold , np_threshold = self . np_threshold , ) lines [ \"offset\" ] = lines [ \"text_with_newline\" ] . str . len () lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"cumsum\" ) lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"shift\" ) lines [ \"offset\" ] = lines [ \"offset\" ] . fillna ( 0 ) . astype ( int ) styles = styles . merge ( lines [[ \"line_id\" , \"offset\" , \"label\" ]], on = \"line_id\" ) styles [ \"start\" ] += styles . offset styles [ \"end\" ] += styles . offset df = lines . groupby ([ \"label\" ]) . agg ( text = ( \"text_with_newline\" , \"sum\" )) text = df . text . to_dict () style = { label : styles . query ( \"label == @label\" ) . drop ( columns = [ \"line_id\" , \"offset\" , \"label\" ]) . to_dict ( orient = \"records\" ) for label in text . keys () } return text , style","title":"StyledAggregator"},{"location":"reference/aggregators/#edspdf.aggregators.base","text":"","title":"base"},{"location":"reference/aggregators/#edspdf.aggregators.base.BaseAggregator","text":"Bases: ABC Source code in edspdf/aggregators/base.py 7 8 9 10 11 12 13 14 15 16 17 class BaseAggregator ( ABC ): @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\" def __call__ ( self , lines : pd . DataFrame , copy : bool = False ) -> Dict [ str , str ]: if copy : lines = lines . copy () return self . aggregate ( lines )","title":"BaseAggregator"},{"location":"reference/aggregators/#edspdf.aggregators.base.BaseAggregator.aggregate","text":"Handles the text aggregation Source code in edspdf/aggregators/base.py 8 9 10 11 12 @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\"","title":"aggregate()"},{"location":"reference/aggregators/base/","text":"edspdf.aggregators.base BaseAggregator Bases: ABC Source code in edspdf/aggregators/base.py 7 8 9 10 11 12 13 14 15 16 17 class BaseAggregator ( ABC ): @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\" def __call__ ( self , lines : pd . DataFrame , copy : bool = False ) -> Dict [ str , str ]: if copy : lines = lines . copy () return self . aggregate ( lines ) aggregate ( lines ) abstractmethod Handles the text aggregation Source code in edspdf/aggregators/base.py 8 9 10 11 12 @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\"","title":"base"},{"location":"reference/aggregators/base/#edspdfaggregatorsbase","text":"","title":"edspdf.aggregators.base"},{"location":"reference/aggregators/base/#edspdf.aggregators.base.BaseAggregator","text":"Bases: ABC Source code in edspdf/aggregators/base.py 7 8 9 10 11 12 13 14 15 16 17 class BaseAggregator ( ABC ): @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\" def __call__ ( self , lines : pd . DataFrame , copy : bool = False ) -> Dict [ str , str ]: if copy : lines = lines . copy () return self . aggregate ( lines )","title":"BaseAggregator"},{"location":"reference/aggregators/base/#edspdf.aggregators.base.BaseAggregator.aggregate","text":"Handles the text aggregation Source code in edspdf/aggregators/base.py 8 9 10 11 12 @abstractmethod def aggregate ( self , lines : pd . DataFrame ) -> Dict [ str , str ]: \"\"\" Handles the text aggregation \"\"\"","title":"aggregate()"},{"location":"reference/aggregators/functional/","text":"edspdf.aggregators.functional","title":"functional"},{"location":"reference/aggregators/functional/#edspdfaggregatorsfunctional","text":"","title":"edspdf.aggregators.functional"},{"location":"reference/aggregators/simple/","text":"edspdf.aggregators.simple","title":"simple"},{"location":"reference/aggregators/simple/#edspdfaggregatorssimple","text":"","title":"edspdf.aggregators.simple"},{"location":"reference/aggregators/styled/","text":"edspdf.aggregators.styled StyledAggregator Bases: SimpleAggregator Aggregator that returns text and styles. Source code in edspdf/aggregators/styled.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @registry . aggregators . register ( \"styled.v1\" ) class StyledAggregator ( SimpleAggregator ): \"\"\" Aggregator that returns text and styles. \"\"\" def aggregate ( self , lines : pd . DataFrame ) -> Tuple [ Dict [ str , str ], Dict [ str , List [ Dict ]]]: lines = lines . sort_values ([ \"page\" , \"y1\" , \"x0\" ]) lines [ \"line_id\" ] = range ( len ( lines )) styles = lines [[ \"line_id\" , \"styles\" ]] . explode ( \"styles\" ) . dropna () . reset_index () styles = styles [[ \"line_id\" ]] . join ( pd . json_normalize ( styles . styles )) lines = prepare_newlines ( lines , nl_threshold = self . nl_threshold , np_threshold = self . np_threshold , ) lines [ \"offset\" ] = lines [ \"text_with_newline\" ] . str . len () lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"cumsum\" ) lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"shift\" ) lines [ \"offset\" ] = lines [ \"offset\" ] . fillna ( 0 ) . astype ( int ) styles = styles . merge ( lines [[ \"line_id\" , \"offset\" , \"label\" ]], on = \"line_id\" ) styles [ \"start\" ] += styles . offset styles [ \"end\" ] += styles . offset df = lines . groupby ([ \"label\" ]) . agg ( text = ( \"text_with_newline\" , \"sum\" )) text = df . text . to_dict () style = { label : styles . query ( \"label == @label\" ) . drop ( columns = [ \"line_id\" , \"offset\" , \"label\" ]) . to_dict ( orient = \"records\" ) for label in text . keys () } return text , style","title":"styled"},{"location":"reference/aggregators/styled/#edspdfaggregatorsstyled","text":"","title":"edspdf.aggregators.styled"},{"location":"reference/aggregators/styled/#edspdf.aggregators.styled.StyledAggregator","text":"Bases: SimpleAggregator Aggregator that returns text and styles. Source code in edspdf/aggregators/styled.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @registry . aggregators . register ( \"styled.v1\" ) class StyledAggregator ( SimpleAggregator ): \"\"\" Aggregator that returns text and styles. \"\"\" def aggregate ( self , lines : pd . DataFrame ) -> Tuple [ Dict [ str , str ], Dict [ str , List [ Dict ]]]: lines = lines . sort_values ([ \"page\" , \"y1\" , \"x0\" ]) lines [ \"line_id\" ] = range ( len ( lines )) styles = lines [[ \"line_id\" , \"styles\" ]] . explode ( \"styles\" ) . dropna () . reset_index () styles = styles [[ \"line_id\" ]] . join ( pd . json_normalize ( styles . styles )) lines = prepare_newlines ( lines , nl_threshold = self . nl_threshold , np_threshold = self . np_threshold , ) lines [ \"offset\" ] = lines [ \"text_with_newline\" ] . str . len () lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"cumsum\" ) lines [ \"offset\" ] = lines . groupby ([ \"label\" ])[ \"offset\" ] . transform ( \"shift\" ) lines [ \"offset\" ] = lines [ \"offset\" ] . fillna ( 0 ) . astype ( int ) styles = styles . merge ( lines [[ \"line_id\" , \"offset\" , \"label\" ]], on = \"line_id\" ) styles [ \"start\" ] += styles . offset styles [ \"end\" ] += styles . offset df = lines . groupby ([ \"label\" ]) . agg ( text = ( \"text_with_newline\" , \"sum\" )) text = df . text . to_dict () style = { label : styles . query ( \"label == @label\" ) . drop ( columns = [ \"line_id\" , \"offset\" , \"label\" ]) . to_dict ( orient = \"records\" ) for label in text . keys () } return text , style","title":"StyledAggregator"},{"location":"reference/classifiers/","text":"edspdf.classifiers align align_labels ( lines , labels , threshold = 0.0001 ) Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all PARAMETER DESCRIPTION lines DataFrame containing the lines TYPE: pd . DataFrame labels DataFrame containing the labels TYPE: pd . DataFrame threshold Threshold to use for discounting a label. Used if the labels DataFrame does not provide a threshold column, or to fill NaN values thereof. TYPE: float, default 1 DEFAULT: 0.0001 RETURNS DESCRIPTION pd . DataFrame A copy of the lines table, with the labels added. Source code in edspdf/classifiers/align.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def align_labels ( lines : pd . DataFrame , labels : pd . DataFrame , threshold : float = 0.0001 , ) -> pd . DataFrame : \"\"\" Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all Parameters ---------- lines : pd.DataFrame DataFrame containing the lines labels : pd.DataFrame DataFrame containing the labels threshold : float, default 1 Threshold to use for discounting a label. Used if the `labels` DataFrame does not provide a `threshold` column, or to fill `NaN` values thereof. Returns ------- pd.DataFrame A copy of the lines table, with the labels added. \"\"\" lines [ \"uid\" ] = range ( len ( lines )) df = lines [ sorted ({ \"uid\" , \"page\" , \"x0\" , \"y0\" , \"x1\" , \"y1\" } & set ( lines . columns )) ] . copy () labels = labels . copy () if \"threshold\" not in labels . columns : labels [ \"threshold\" ] = threshold labels . threshold = labels . threshold . fillna ( threshold ) df = df . merge ( labels , how = \"inner\" if set ( df . columns ) & set ( labels . columns ) else \"cross\" ) df [ \"dx\" ] = df [[ \"x1\" , \"X1\" ]] . min ( axis = 1 ) - df [[ \"x0\" , \"X0\" ]] . max ( axis = 1 ) df [ \"dy\" ] = df [[ \"y1\" , \"Y1\" ]] . min ( axis = 1 ) - df [[ \"y0\" , \"Y0\" ]] . max ( axis = 1 ) df [ \"overlap\" ] = ( df . dx > 0 ) * ( df . dy > 0 ) * df . dx * df . dy df [ \"area\" ] = ( df . x1 - df . x0 ) * ( df . y1 - df . y0 ) df [ \"ratio\" ] = df . overlap / df . area df [ \"area_mask\" ] = ( df . X1 - df . X0 ) * ( df . Y1 - df . Y0 ) df [ \"ratio_mask\" ] = df . overlap / df . area_mask df [ \"thresholded\" ] = df . ratio >= df . threshold df = df . sort_values ([ \"thresholded\" , \"ratio_mask\" ], ascending = False ) df = df . groupby ([ \"uid\" ], as_index = False ) . first () df = df . sort_values ( \"uid\" ) . reset_index ( drop = True ) df . label = df . label . where ( df . thresholded ) df = lines . merge ( df [[ \"uid\" , \"label\" ]], on = \"uid\" ) . drop ( columns = [ \"uid\" ]) lines . drop ( columns = \"uid\" , inplace = True ) return df base BaseClassifier Bases: ABC Source code in edspdf/classifiers/base.py 7 8 9 10 11 12 13 14 15 class BaseClassifier ( ABC ): @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> List [ str ]: return self . predict ( lines ) predict ( lines ) abstractmethod Handles the classification. Source code in edspdf/classifiers/base.py 8 9 10 11 12 @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" dummy DummyClassifier Bases: BaseClassifier \"Dummy\" classifier, for testing purposes. Classifies every line to body . Source code in edspdf/classifiers/dummy.py 10 11 12 13 14 15 16 17 @registry . classifiers . register ( \"dummy.v1\" ) class DummyClassifier ( BaseClassifier ): \"\"\" \"Dummy\" classifier, for testing purposes. Classifies every line to ``body``. \"\"\" def predict ( self , lines : pd . DataFrame ) -> List [ str ]: return [ \"body\" ] * len ( lines ) random RandomClassifier Bases: BaseClassifier Random classifier, for chaos purposes. Classifies each line to a random element. Source code in edspdf/classifiers/random.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @registry . classifiers . register ( \"random.v1\" ) class RandomClassifier ( BaseClassifier ): \"\"\" Random classifier, for chaos purposes. Classifies each line to a random element. \"\"\" def __init__ ( self , classes : Union [ List [ str ], Dict [ str , float ]], seed : Optional [ int ] = 0 , ) -> None : if isinstance ( classes , list ): classes = { c : 1 for c in classes } self . classes = { c : w / sum ( classes . values ()) for c , w in classes . items ()} self . rgn = np . random . default_rng ( seed = seed ) def predict ( self , lines : pd . DataFrame ) -> List [ str ]: choices = self . rgn . choice ( list ( self . classes . keys ()), p = list ( self . classes . values ()), size = len ( lines ), ) return list ( choices ) mask MaskClassifier Bases: BaseClassifier Mask classifier, that reproduces the PdfBox behaviour. Source code in edspdf/classifiers/mask.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class MaskClassifier ( BaseClassifier ): \"\"\" Mask classifier, that reproduces the PdfBox behaviour. \"\"\" def __init__ ( self , * ms : Mask , ) -> None : masks = list ( ms ) masks . append ( Mask ( label = \"pollution\" )) self . comparison = pd . DataFrame . from_records ([ mask . dict () for mask in masks ]) def predict ( self , lines : pd . DataFrame ) -> pd . Series : df = align_labels ( lines , self . comparison ) return df . label","title":"`edspdf.classifiers`"},{"location":"reference/classifiers/#edspdfclassifiers","text":"","title":"edspdf.classifiers"},{"location":"reference/classifiers/#edspdf.classifiers.align","text":"","title":"align"},{"location":"reference/classifiers/#edspdf.classifiers.align.align_labels","text":"Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all PARAMETER DESCRIPTION lines DataFrame containing the lines TYPE: pd . DataFrame labels DataFrame containing the labels TYPE: pd . DataFrame threshold Threshold to use for discounting a label. Used if the labels DataFrame does not provide a threshold column, or to fill NaN values thereof. TYPE: float, default 1 DEFAULT: 0.0001 RETURNS DESCRIPTION pd . DataFrame A copy of the lines table, with the labels added. Source code in edspdf/classifiers/align.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def align_labels ( lines : pd . DataFrame , labels : pd . DataFrame , threshold : float = 0.0001 , ) -> pd . DataFrame : \"\"\" Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all Parameters ---------- lines : pd.DataFrame DataFrame containing the lines labels : pd.DataFrame DataFrame containing the labels threshold : float, default 1 Threshold to use for discounting a label. Used if the `labels` DataFrame does not provide a `threshold` column, or to fill `NaN` values thereof. Returns ------- pd.DataFrame A copy of the lines table, with the labels added. \"\"\" lines [ \"uid\" ] = range ( len ( lines )) df = lines [ sorted ({ \"uid\" , \"page\" , \"x0\" , \"y0\" , \"x1\" , \"y1\" } & set ( lines . columns )) ] . copy () labels = labels . copy () if \"threshold\" not in labels . columns : labels [ \"threshold\" ] = threshold labels . threshold = labels . threshold . fillna ( threshold ) df = df . merge ( labels , how = \"inner\" if set ( df . columns ) & set ( labels . columns ) else \"cross\" ) df [ \"dx\" ] = df [[ \"x1\" , \"X1\" ]] . min ( axis = 1 ) - df [[ \"x0\" , \"X0\" ]] . max ( axis = 1 ) df [ \"dy\" ] = df [[ \"y1\" , \"Y1\" ]] . min ( axis = 1 ) - df [[ \"y0\" , \"Y0\" ]] . max ( axis = 1 ) df [ \"overlap\" ] = ( df . dx > 0 ) * ( df . dy > 0 ) * df . dx * df . dy df [ \"area\" ] = ( df . x1 - df . x0 ) * ( df . y1 - df . y0 ) df [ \"ratio\" ] = df . overlap / df . area df [ \"area_mask\" ] = ( df . X1 - df . X0 ) * ( df . Y1 - df . Y0 ) df [ \"ratio_mask\" ] = df . overlap / df . area_mask df [ \"thresholded\" ] = df . ratio >= df . threshold df = df . sort_values ([ \"thresholded\" , \"ratio_mask\" ], ascending = False ) df = df . groupby ([ \"uid\" ], as_index = False ) . first () df = df . sort_values ( \"uid\" ) . reset_index ( drop = True ) df . label = df . label . where ( df . thresholded ) df = lines . merge ( df [[ \"uid\" , \"label\" ]], on = \"uid\" ) . drop ( columns = [ \"uid\" ]) lines . drop ( columns = \"uid\" , inplace = True ) return df","title":"align_labels()"},{"location":"reference/classifiers/#edspdf.classifiers.base","text":"","title":"base"},{"location":"reference/classifiers/#edspdf.classifiers.base.BaseClassifier","text":"Bases: ABC Source code in edspdf/classifiers/base.py 7 8 9 10 11 12 13 14 15 class BaseClassifier ( ABC ): @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> List [ str ]: return self . predict ( lines )","title":"BaseClassifier"},{"location":"reference/classifiers/#edspdf.classifiers.base.BaseClassifier.predict","text":"Handles the classification. Source code in edspdf/classifiers/base.py 8 9 10 11 12 @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\"","title":"predict()"},{"location":"reference/classifiers/#edspdf.classifiers.dummy","text":"","title":"dummy"},{"location":"reference/classifiers/#edspdf.classifiers.dummy.DummyClassifier","text":"Bases: BaseClassifier \"Dummy\" classifier, for testing purposes. Classifies every line to body . Source code in edspdf/classifiers/dummy.py 10 11 12 13 14 15 16 17 @registry . classifiers . register ( \"dummy.v1\" ) class DummyClassifier ( BaseClassifier ): \"\"\" \"Dummy\" classifier, for testing purposes. Classifies every line to ``body``. \"\"\" def predict ( self , lines : pd . DataFrame ) -> List [ str ]: return [ \"body\" ] * len ( lines )","title":"DummyClassifier"},{"location":"reference/classifiers/#edspdf.classifiers.random","text":"","title":"random"},{"location":"reference/classifiers/#edspdf.classifiers.random.RandomClassifier","text":"Bases: BaseClassifier Random classifier, for chaos purposes. Classifies each line to a random element. Source code in edspdf/classifiers/random.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @registry . classifiers . register ( \"random.v1\" ) class RandomClassifier ( BaseClassifier ): \"\"\" Random classifier, for chaos purposes. Classifies each line to a random element. \"\"\" def __init__ ( self , classes : Union [ List [ str ], Dict [ str , float ]], seed : Optional [ int ] = 0 , ) -> None : if isinstance ( classes , list ): classes = { c : 1 for c in classes } self . classes = { c : w / sum ( classes . values ()) for c , w in classes . items ()} self . rgn = np . random . default_rng ( seed = seed ) def predict ( self , lines : pd . DataFrame ) -> List [ str ]: choices = self . rgn . choice ( list ( self . classes . keys ()), p = list ( self . classes . values ()), size = len ( lines ), ) return list ( choices )","title":"RandomClassifier"},{"location":"reference/classifiers/#edspdf.classifiers.mask","text":"","title":"mask"},{"location":"reference/classifiers/#edspdf.classifiers.mask.MaskClassifier","text":"Bases: BaseClassifier Mask classifier, that reproduces the PdfBox behaviour. Source code in edspdf/classifiers/mask.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class MaskClassifier ( BaseClassifier ): \"\"\" Mask classifier, that reproduces the PdfBox behaviour. \"\"\" def __init__ ( self , * ms : Mask , ) -> None : masks = list ( ms ) masks . append ( Mask ( label = \"pollution\" )) self . comparison = pd . DataFrame . from_records ([ mask . dict () for mask in masks ]) def predict ( self , lines : pd . DataFrame ) -> pd . Series : df = align_labels ( lines , self . comparison ) return df . label","title":"MaskClassifier"},{"location":"reference/classifiers/align/","text":"edspdf.classifiers.align align_labels ( lines , labels , threshold = 0.0001 ) Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all PARAMETER DESCRIPTION lines DataFrame containing the lines TYPE: pd . DataFrame labels DataFrame containing the labels TYPE: pd . DataFrame threshold Threshold to use for discounting a label. Used if the labels DataFrame does not provide a threshold column, or to fill NaN values thereof. TYPE: float, default 1 DEFAULT: 0.0001 RETURNS DESCRIPTION pd . DataFrame A copy of the lines table, with the labels added. Source code in edspdf/classifiers/align.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def align_labels ( lines : pd . DataFrame , labels : pd . DataFrame , threshold : float = 0.0001 , ) -> pd . DataFrame : \"\"\" Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all Parameters ---------- lines : pd.DataFrame DataFrame containing the lines labels : pd.DataFrame DataFrame containing the labels threshold : float, default 1 Threshold to use for discounting a label. Used if the `labels` DataFrame does not provide a `threshold` column, or to fill `NaN` values thereof. Returns ------- pd.DataFrame A copy of the lines table, with the labels added. \"\"\" lines [ \"uid\" ] = range ( len ( lines )) df = lines [ sorted ({ \"uid\" , \"page\" , \"x0\" , \"y0\" , \"x1\" , \"y1\" } & set ( lines . columns )) ] . copy () labels = labels . copy () if \"threshold\" not in labels . columns : labels [ \"threshold\" ] = threshold labels . threshold = labels . threshold . fillna ( threshold ) df = df . merge ( labels , how = \"inner\" if set ( df . columns ) & set ( labels . columns ) else \"cross\" ) df [ \"dx\" ] = df [[ \"x1\" , \"X1\" ]] . min ( axis = 1 ) - df [[ \"x0\" , \"X0\" ]] . max ( axis = 1 ) df [ \"dy\" ] = df [[ \"y1\" , \"Y1\" ]] . min ( axis = 1 ) - df [[ \"y0\" , \"Y0\" ]] . max ( axis = 1 ) df [ \"overlap\" ] = ( df . dx > 0 ) * ( df . dy > 0 ) * df . dx * df . dy df [ \"area\" ] = ( df . x1 - df . x0 ) * ( df . y1 - df . y0 ) df [ \"ratio\" ] = df . overlap / df . area df [ \"area_mask\" ] = ( df . X1 - df . X0 ) * ( df . Y1 - df . Y0 ) df [ \"ratio_mask\" ] = df . overlap / df . area_mask df [ \"thresholded\" ] = df . ratio >= df . threshold df = df . sort_values ([ \"thresholded\" , \"ratio_mask\" ], ascending = False ) df = df . groupby ([ \"uid\" ], as_index = False ) . first () df = df . sort_values ( \"uid\" ) . reset_index ( drop = True ) df . label = df . label . where ( df . thresholded ) df = lines . merge ( df [[ \"uid\" , \"label\" ]], on = \"uid\" ) . drop ( columns = [ \"uid\" ]) lines . drop ( columns = \"uid\" , inplace = True ) return df","title":"align"},{"location":"reference/classifiers/align/#edspdfclassifiersalign","text":"","title":"edspdf.classifiers.align"},{"location":"reference/classifiers/align/#edspdf.classifiers.align.align_labels","text":"Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all PARAMETER DESCRIPTION lines DataFrame containing the lines TYPE: pd . DataFrame labels DataFrame containing the labels TYPE: pd . DataFrame threshold Threshold to use for discounting a label. Used if the labels DataFrame does not provide a threshold column, or to fill NaN values thereof. TYPE: float, default 1 DEFAULT: 0.0001 RETURNS DESCRIPTION pd . DataFrame A copy of the lines table, with the labels added. Source code in edspdf/classifiers/align.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def align_labels ( lines : pd . DataFrame , labels : pd . DataFrame , threshold : float = 0.0001 , ) -> pd . DataFrame : \"\"\" Align lines with possibly overlapping (and non-exhaustive) labels. Possible matches are sorted by covered area. Lines with no overlap at all Parameters ---------- lines : pd.DataFrame DataFrame containing the lines labels : pd.DataFrame DataFrame containing the labels threshold : float, default 1 Threshold to use for discounting a label. Used if the `labels` DataFrame does not provide a `threshold` column, or to fill `NaN` values thereof. Returns ------- pd.DataFrame A copy of the lines table, with the labels added. \"\"\" lines [ \"uid\" ] = range ( len ( lines )) df = lines [ sorted ({ \"uid\" , \"page\" , \"x0\" , \"y0\" , \"x1\" , \"y1\" } & set ( lines . columns )) ] . copy () labels = labels . copy () if \"threshold\" not in labels . columns : labels [ \"threshold\" ] = threshold labels . threshold = labels . threshold . fillna ( threshold ) df = df . merge ( labels , how = \"inner\" if set ( df . columns ) & set ( labels . columns ) else \"cross\" ) df [ \"dx\" ] = df [[ \"x1\" , \"X1\" ]] . min ( axis = 1 ) - df [[ \"x0\" , \"X0\" ]] . max ( axis = 1 ) df [ \"dy\" ] = df [[ \"y1\" , \"Y1\" ]] . min ( axis = 1 ) - df [[ \"y0\" , \"Y0\" ]] . max ( axis = 1 ) df [ \"overlap\" ] = ( df . dx > 0 ) * ( df . dy > 0 ) * df . dx * df . dy df [ \"area\" ] = ( df . x1 - df . x0 ) * ( df . y1 - df . y0 ) df [ \"ratio\" ] = df . overlap / df . area df [ \"area_mask\" ] = ( df . X1 - df . X0 ) * ( df . Y1 - df . Y0 ) df [ \"ratio_mask\" ] = df . overlap / df . area_mask df [ \"thresholded\" ] = df . ratio >= df . threshold df = df . sort_values ([ \"thresholded\" , \"ratio_mask\" ], ascending = False ) df = df . groupby ([ \"uid\" ], as_index = False ) . first () df = df . sort_values ( \"uid\" ) . reset_index ( drop = True ) df . label = df . label . where ( df . thresholded ) df = lines . merge ( df [[ \"uid\" , \"label\" ]], on = \"uid\" ) . drop ( columns = [ \"uid\" ]) lines . drop ( columns = \"uid\" , inplace = True ) return df","title":"align_labels()"},{"location":"reference/classifiers/base/","text":"edspdf.classifiers.base BaseClassifier Bases: ABC Source code in edspdf/classifiers/base.py 7 8 9 10 11 12 13 14 15 class BaseClassifier ( ABC ): @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> List [ str ]: return self . predict ( lines ) predict ( lines ) abstractmethod Handles the classification. Source code in edspdf/classifiers/base.py 8 9 10 11 12 @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\"","title":"base"},{"location":"reference/classifiers/base/#edspdfclassifiersbase","text":"","title":"edspdf.classifiers.base"},{"location":"reference/classifiers/base/#edspdf.classifiers.base.BaseClassifier","text":"Bases: ABC Source code in edspdf/classifiers/base.py 7 8 9 10 11 12 13 14 15 class BaseClassifier ( ABC ): @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> List [ str ]: return self . predict ( lines )","title":"BaseClassifier"},{"location":"reference/classifiers/base/#edspdf.classifiers.base.BaseClassifier.predict","text":"Handles the classification. Source code in edspdf/classifiers/base.py 8 9 10 11 12 @abstractmethod def predict ( self , lines : pd . DataFrame ) -> List [ str ]: \"\"\" Handles the classification. \"\"\"","title":"predict()"},{"location":"reference/classifiers/dummy/","text":"edspdf.classifiers.dummy DummyClassifier Bases: BaseClassifier \"Dummy\" classifier, for testing purposes. Classifies every line to body . Source code in edspdf/classifiers/dummy.py 10 11 12 13 14 15 16 17 @registry . classifiers . register ( \"dummy.v1\" ) class DummyClassifier ( BaseClassifier ): \"\"\" \"Dummy\" classifier, for testing purposes. Classifies every line to ``body``. \"\"\" def predict ( self , lines : pd . DataFrame ) -> List [ str ]: return [ \"body\" ] * len ( lines )","title":"dummy"},{"location":"reference/classifiers/dummy/#edspdfclassifiersdummy","text":"","title":"edspdf.classifiers.dummy"},{"location":"reference/classifiers/dummy/#edspdf.classifiers.dummy.DummyClassifier","text":"Bases: BaseClassifier \"Dummy\" classifier, for testing purposes. Classifies every line to body . Source code in edspdf/classifiers/dummy.py 10 11 12 13 14 15 16 17 @registry . classifiers . register ( \"dummy.v1\" ) class DummyClassifier ( BaseClassifier ): \"\"\" \"Dummy\" classifier, for testing purposes. Classifies every line to ``body``. \"\"\" def predict ( self , lines : pd . DataFrame ) -> List [ str ]: return [ \"body\" ] * len ( lines )","title":"DummyClassifier"},{"location":"reference/classifiers/mask/","text":"edspdf.classifiers.mask MaskClassifier Bases: BaseClassifier Mask classifier, that reproduces the PdfBox behaviour. Source code in edspdf/classifiers/mask.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class MaskClassifier ( BaseClassifier ): \"\"\" Mask classifier, that reproduces the PdfBox behaviour. \"\"\" def __init__ ( self , * ms : Mask , ) -> None : masks = list ( ms ) masks . append ( Mask ( label = \"pollution\" )) self . comparison = pd . DataFrame . from_records ([ mask . dict () for mask in masks ]) def predict ( self , lines : pd . DataFrame ) -> pd . Series : df = align_labels ( lines , self . comparison ) return df . label","title":"mask"},{"location":"reference/classifiers/mask/#edspdfclassifiersmask","text":"","title":"edspdf.classifiers.mask"},{"location":"reference/classifiers/mask/#edspdf.classifiers.mask.MaskClassifier","text":"Bases: BaseClassifier Mask classifier, that reproduces the PdfBox behaviour. Source code in edspdf/classifiers/mask.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class MaskClassifier ( BaseClassifier ): \"\"\" Mask classifier, that reproduces the PdfBox behaviour. \"\"\" def __init__ ( self , * ms : Mask , ) -> None : masks = list ( ms ) masks . append ( Mask ( label = \"pollution\" )) self . comparison = pd . DataFrame . from_records ([ mask . dict () for mask in masks ]) def predict ( self , lines : pd . DataFrame ) -> pd . Series : df = align_labels ( lines , self . comparison ) return df . label","title":"MaskClassifier"},{"location":"reference/classifiers/random/","text":"edspdf.classifiers.random RandomClassifier Bases: BaseClassifier Random classifier, for chaos purposes. Classifies each line to a random element. Source code in edspdf/classifiers/random.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @registry . classifiers . register ( \"random.v1\" ) class RandomClassifier ( BaseClassifier ): \"\"\" Random classifier, for chaos purposes. Classifies each line to a random element. \"\"\" def __init__ ( self , classes : Union [ List [ str ], Dict [ str , float ]], seed : Optional [ int ] = 0 , ) -> None : if isinstance ( classes , list ): classes = { c : 1 for c in classes } self . classes = { c : w / sum ( classes . values ()) for c , w in classes . items ()} self . rgn = np . random . default_rng ( seed = seed ) def predict ( self , lines : pd . DataFrame ) -> List [ str ]: choices = self . rgn . choice ( list ( self . classes . keys ()), p = list ( self . classes . values ()), size = len ( lines ), ) return list ( choices )","title":"random"},{"location":"reference/classifiers/random/#edspdfclassifiersrandom","text":"","title":"edspdf.classifiers.random"},{"location":"reference/classifiers/random/#edspdf.classifiers.random.RandomClassifier","text":"Bases: BaseClassifier Random classifier, for chaos purposes. Classifies each line to a random element. Source code in edspdf/classifiers/random.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @registry . classifiers . register ( \"random.v1\" ) class RandomClassifier ( BaseClassifier ): \"\"\" Random classifier, for chaos purposes. Classifies each line to a random element. \"\"\" def __init__ ( self , classes : Union [ List [ str ], Dict [ str , float ]], seed : Optional [ int ] = 0 , ) -> None : if isinstance ( classes , list ): classes = { c : 1 for c in classes } self . classes = { c : w / sum ( classes . values ()) for c , w in classes . items ()} self . rgn = np . random . default_rng ( seed = seed ) def predict ( self , lines : pd . DataFrame ) -> List [ str ]: choices = self . rgn . choice ( list ( self . classes . keys ()), p = list ( self . classes . values ()), size = len ( lines ), ) return list ( choices )","title":"RandomClassifier"},{"location":"reference/classifiers/sklearn/","text":"edspdf.classifiers.sklearn","title":"sklearn"},{"location":"reference/classifiers/sklearn/#edspdfclassifierssklearn","text":"","title":"edspdf.classifiers.sklearn"},{"location":"reference/extractors/","text":"edspdf.extractors pdfminer PdfMinerExtractor Bases: BaseExtractor Extractor object. Given a PDF byte stream, produces a list of blocs. PARAMETER DESCRIPTION line_overlap See PDFMiner documentation TYPE: float DEFAULT: 0.5 char_margin See PDFMiner documentation TYPE: float DEFAULT: 2.0 line_margin See PDFMiner documentation TYPE: float DEFAULT: 0.5 word_margin See PDFMiner documentation TYPE: float DEFAULT: 0.1 boxes_flow See PDFMiner documentation TYPE: Optional [ float ] DEFAULT: 0.5 detect_vertical See PDFMiner documentation TYPE: bool DEFAULT: False all_texts See PDFMiner documentation TYPE: bool DEFAULT: False Source code in edspdf/extractors/pdfminer.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @registry . extractors . register ( \"pdfminer.v1\" ) class PdfMinerExtractor ( BaseExtractor ): \"\"\" Extractor object. Given a PDF byte stream, produces a list of blocs. Parameters ---------- line_overlap : float See PDFMiner documentation char_margin : float See PDFMiner documentation line_margin : float See PDFMiner documentation word_margin : float See PDFMiner documentation boxes_flow : Optional[float] See PDFMiner documentation detect_vertical : bool See PDFMiner documentation all_texts : bool See PDFMiner documentation \"\"\" def __init__ ( self , line_overlap : float = 0.5 , char_margin : float = 2.0 , line_margin : float = 0.5 , word_margin : float = 0.1 , boxes_flow : Optional [ float ] = 0.5 , detect_vertical : bool = False , all_texts : bool = False , ): self . laparams = LAParams ( line_overlap = line_overlap , char_margin = char_margin , line_margin = line_margin , word_margin = word_margin , boxes_flow = boxes_flow , detect_vertical = detect_vertical , all_texts = all_texts , ) def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines generate_lines ( pdf ) Generates dataframe from all blocs in the PDF. Arguments pdf: Byte stream representing the PDF. RETURNS DESCRIPTION pd . DataFrame DataFrame representing the blocs. Source code in edspdf/extractors/pdfminer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df extract ( pdf ) Process a single PDF document. PARAMETER DESCRIPTION pdf Raw byte representation of the PDF document. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame DataFrame containing one row for each line extracted using PDFMiner. Source code in edspdf/extractors/pdfminer.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines base BaseExtractor Bases: ABC Source code in edspdf/extractors/base.py 6 7 8 9 10 11 12 13 14 class BaseExtractor ( ABC ): @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" def __call__ ( self , pdf : bytes ) -> pd . DataFrame : return self . extract ( pdf ) extract ( pdf ) abstractmethod Handles the extraction Source code in edspdf/extractors/base.py 7 8 9 10 11 @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" functional get_blocs ( layout ) Extract text blocs from a PDFMiner layout generator. Arguments layout: PDFMiner layout generator. YIELDS DESCRIPTION bloc Text bloc TYPE: Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]] Source code in edspdf/extractors/functional.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_blocs ( layout : Iterator [ LTPage ], ) -> Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]]: \"\"\" Extract text blocs from a PDFMiner layout generator. Arguments --------- layout: PDFMiner layout generator. Yields ------ bloc : Text bloc \"\"\" for i , page in enumerate ( layout ): width = page . width height = page . height for bloc in page : if isinstance ( bloc , LTTextBoxHorizontal ): yield bloc , i , width , height get_lines ( layout ) Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. PARAMETER DESCRIPTION layout PDFMiner layout object. TYPE: Iterator [ LTPage ] YIELDS DESCRIPTION Iterator [ Line ] Single line object. Source code in edspdf/extractors/functional.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_lines ( layout : Iterator [ LTPage ]) -> Iterator [ Line ]: \"\"\" Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. Parameters ---------- layout : Iterator[LTPage] PDFMiner layout object. Yields ------- Iterator[Line] Single line object. \"\"\" for b , ( bloc , p , w , h ) in enumerate ( get_blocs ( layout )): for line in bloc : text , styles = extract_style ( line , width = w , height = h ) yield Line ( page = p , bloc = b , x0 = line . x0 / w , x1 = line . x1 / w , y0 = 1 - line . y1 / h , y1 = 1 - line . y0 / h , page_width = w , page_height = h , text = text , styles = styles , ) remove_outside_lines ( lines , strict_mode = False ) Filter out lines that are outside the canvas. PARAMETER DESCRIPTION lines Dataframe of extracted lines TYPE: pd . DataFrame strict_mode Whether to remove the line if any part of it is outside the canvas, by default False TYPE: bool , optional DEFAULT: False RETURNS DESCRIPTION pd . DataFrame Filtered lines. Source code in edspdf/extractors/functional.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def remove_outside_lines ( lines : pd . DataFrame , strict_mode : bool = False , ) -> pd . DataFrame : \"\"\" Filter out lines that are outside the canvas. Parameters ---------- lines : pd.DataFrame Dataframe of extracted lines strict_mode : bool, optional Whether to remove the line if any part of it is outside the canvas, by default False Returns ------- pd.DataFrame Filtered lines. \"\"\" if strict_mode : lower = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) >= 0 upper = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) <= 1 lines = lines [ lower & upper ] else : below = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) < 0 above = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) > 0 lines = lines [ ~ ( below | above )] return lines style models BaseStyle Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float Style Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st from_fontname ( fontname , size , upright , x0 , x1 , y0 , y1 ) classmethod Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s __eq__ ( other ) Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o StyledText Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"`edspdf.extractors`"},{"location":"reference/extractors/#edspdfextractors","text":"","title":"edspdf.extractors"},{"location":"reference/extractors/#edspdf.extractors.pdfminer","text":"","title":"pdfminer"},{"location":"reference/extractors/#edspdf.extractors.pdfminer.PdfMinerExtractor","text":"Bases: BaseExtractor Extractor object. Given a PDF byte stream, produces a list of blocs. PARAMETER DESCRIPTION line_overlap See PDFMiner documentation TYPE: float DEFAULT: 0.5 char_margin See PDFMiner documentation TYPE: float DEFAULT: 2.0 line_margin See PDFMiner documentation TYPE: float DEFAULT: 0.5 word_margin See PDFMiner documentation TYPE: float DEFAULT: 0.1 boxes_flow See PDFMiner documentation TYPE: Optional [ float ] DEFAULT: 0.5 detect_vertical See PDFMiner documentation TYPE: bool DEFAULT: False all_texts See PDFMiner documentation TYPE: bool DEFAULT: False Source code in edspdf/extractors/pdfminer.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @registry . extractors . register ( \"pdfminer.v1\" ) class PdfMinerExtractor ( BaseExtractor ): \"\"\" Extractor object. Given a PDF byte stream, produces a list of blocs. Parameters ---------- line_overlap : float See PDFMiner documentation char_margin : float See PDFMiner documentation line_margin : float See PDFMiner documentation word_margin : float See PDFMiner documentation boxes_flow : Optional[float] See PDFMiner documentation detect_vertical : bool See PDFMiner documentation all_texts : bool See PDFMiner documentation \"\"\" def __init__ ( self , line_overlap : float = 0.5 , char_margin : float = 2.0 , line_margin : float = 0.5 , word_margin : float = 0.1 , boxes_flow : Optional [ float ] = 0.5 , detect_vertical : bool = False , all_texts : bool = False , ): self . laparams = LAParams ( line_overlap = line_overlap , char_margin = char_margin , line_margin = line_margin , word_margin = word_margin , boxes_flow = boxes_flow , detect_vertical = detect_vertical , all_texts = all_texts , ) def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines","title":"PdfMinerExtractor"},{"location":"reference/extractors/#edspdf.extractors.pdfminer.PdfMinerExtractor.generate_lines","text":"Generates dataframe from all blocs in the PDF.","title":"generate_lines()"},{"location":"reference/extractors/#edspdf.extractors.pdfminer.PdfMinerExtractor.generate_lines--arguments","text":"pdf: Byte stream representing the PDF. RETURNS DESCRIPTION pd . DataFrame DataFrame representing the blocs. Source code in edspdf/extractors/pdfminer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df","title":"Arguments"},{"location":"reference/extractors/#edspdf.extractors.pdfminer.PdfMinerExtractor.extract","text":"Process a single PDF document. PARAMETER DESCRIPTION pdf Raw byte representation of the PDF document. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame DataFrame containing one row for each line extracted using PDFMiner. Source code in edspdf/extractors/pdfminer.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines","title":"extract()"},{"location":"reference/extractors/#edspdf.extractors.base","text":"","title":"base"},{"location":"reference/extractors/#edspdf.extractors.base.BaseExtractor","text":"Bases: ABC Source code in edspdf/extractors/base.py 6 7 8 9 10 11 12 13 14 class BaseExtractor ( ABC ): @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" def __call__ ( self , pdf : bytes ) -> pd . DataFrame : return self . extract ( pdf )","title":"BaseExtractor"},{"location":"reference/extractors/#edspdf.extractors.base.BaseExtractor.extract","text":"Handles the extraction Source code in edspdf/extractors/base.py 7 8 9 10 11 @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\"","title":"extract()"},{"location":"reference/extractors/#edspdf.extractors.functional","text":"","title":"functional"},{"location":"reference/extractors/#edspdf.extractors.functional.get_blocs","text":"Extract text blocs from a PDFMiner layout generator.","title":"get_blocs()"},{"location":"reference/extractors/#edspdf.extractors.functional.get_blocs--arguments","text":"layout: PDFMiner layout generator. YIELDS DESCRIPTION bloc Text bloc TYPE: Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]] Source code in edspdf/extractors/functional.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_blocs ( layout : Iterator [ LTPage ], ) -> Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]]: \"\"\" Extract text blocs from a PDFMiner layout generator. Arguments --------- layout: PDFMiner layout generator. Yields ------ bloc : Text bloc \"\"\" for i , page in enumerate ( layout ): width = page . width height = page . height for bloc in page : if isinstance ( bloc , LTTextBoxHorizontal ): yield bloc , i , width , height","title":"Arguments"},{"location":"reference/extractors/#edspdf.extractors.functional.get_lines","text":"Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. PARAMETER DESCRIPTION layout PDFMiner layout object. TYPE: Iterator [ LTPage ] YIELDS DESCRIPTION Iterator [ Line ] Single line object. Source code in edspdf/extractors/functional.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_lines ( layout : Iterator [ LTPage ]) -> Iterator [ Line ]: \"\"\" Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. Parameters ---------- layout : Iterator[LTPage] PDFMiner layout object. Yields ------- Iterator[Line] Single line object. \"\"\" for b , ( bloc , p , w , h ) in enumerate ( get_blocs ( layout )): for line in bloc : text , styles = extract_style ( line , width = w , height = h ) yield Line ( page = p , bloc = b , x0 = line . x0 / w , x1 = line . x1 / w , y0 = 1 - line . y1 / h , y1 = 1 - line . y0 / h , page_width = w , page_height = h , text = text , styles = styles , )","title":"get_lines()"},{"location":"reference/extractors/#edspdf.extractors.functional.remove_outside_lines","text":"Filter out lines that are outside the canvas. PARAMETER DESCRIPTION lines Dataframe of extracted lines TYPE: pd . DataFrame strict_mode Whether to remove the line if any part of it is outside the canvas, by default False TYPE: bool , optional DEFAULT: False RETURNS DESCRIPTION pd . DataFrame Filtered lines. Source code in edspdf/extractors/functional.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def remove_outside_lines ( lines : pd . DataFrame , strict_mode : bool = False , ) -> pd . DataFrame : \"\"\" Filter out lines that are outside the canvas. Parameters ---------- lines : pd.DataFrame Dataframe of extracted lines strict_mode : bool, optional Whether to remove the line if any part of it is outside the canvas, by default False Returns ------- pd.DataFrame Filtered lines. \"\"\" if strict_mode : lower = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) >= 0 upper = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) <= 1 lines = lines [ lower & upper ] else : below = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) < 0 above = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) > 0 lines = lines [ ~ ( below | above )] return lines","title":"remove_outside_lines()"},{"location":"reference/extractors/#edspdf.extractors.style","text":"","title":"style"},{"location":"reference/extractors/#edspdf.extractors.style.models","text":"","title":"models"},{"location":"reference/extractors/#edspdf.extractors.style.models.BaseStyle","text":"Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float","title":"BaseStyle"},{"location":"reference/extractors/#edspdf.extractors.style.models.Style","text":"Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st","title":"Style"},{"location":"reference/extractors/#edspdf.extractors.style.models.Style.from_fontname","text":"Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s","title":"from_fontname()"},{"location":"reference/extractors/#edspdf.extractors.style.models.Style.__eq__","text":"Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o","title":"__eq__()"},{"location":"reference/extractors/#edspdf.extractors.style.models.StyledText","text":"Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"StyledText"},{"location":"reference/extractors/base/","text":"edspdf.extractors.base BaseExtractor Bases: ABC Source code in edspdf/extractors/base.py 6 7 8 9 10 11 12 13 14 class BaseExtractor ( ABC ): @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" def __call__ ( self , pdf : bytes ) -> pd . DataFrame : return self . extract ( pdf ) extract ( pdf ) abstractmethod Handles the extraction Source code in edspdf/extractors/base.py 7 8 9 10 11 @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\"","title":"base"},{"location":"reference/extractors/base/#edspdfextractorsbase","text":"","title":"edspdf.extractors.base"},{"location":"reference/extractors/base/#edspdf.extractors.base.BaseExtractor","text":"Bases: ABC Source code in edspdf/extractors/base.py 6 7 8 9 10 11 12 13 14 class BaseExtractor ( ABC ): @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\" def __call__ ( self , pdf : bytes ) -> pd . DataFrame : return self . extract ( pdf )","title":"BaseExtractor"},{"location":"reference/extractors/base/#edspdf.extractors.base.BaseExtractor.extract","text":"Handles the extraction Source code in edspdf/extractors/base.py 7 8 9 10 11 @abstractmethod def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Handles the extraction \"\"\"","title":"extract()"},{"location":"reference/extractors/functional/","text":"edspdf.extractors.functional get_blocs ( layout ) Extract text blocs from a PDFMiner layout generator. Arguments layout: PDFMiner layout generator. YIELDS DESCRIPTION bloc Text bloc TYPE: Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]] Source code in edspdf/extractors/functional.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_blocs ( layout : Iterator [ LTPage ], ) -> Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]]: \"\"\" Extract text blocs from a PDFMiner layout generator. Arguments --------- layout: PDFMiner layout generator. Yields ------ bloc : Text bloc \"\"\" for i , page in enumerate ( layout ): width = page . width height = page . height for bloc in page : if isinstance ( bloc , LTTextBoxHorizontal ): yield bloc , i , width , height get_lines ( layout ) Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. PARAMETER DESCRIPTION layout PDFMiner layout object. TYPE: Iterator [ LTPage ] YIELDS DESCRIPTION Iterator [ Line ] Single line object. Source code in edspdf/extractors/functional.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_lines ( layout : Iterator [ LTPage ]) -> Iterator [ Line ]: \"\"\" Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. Parameters ---------- layout : Iterator[LTPage] PDFMiner layout object. Yields ------- Iterator[Line] Single line object. \"\"\" for b , ( bloc , p , w , h ) in enumerate ( get_blocs ( layout )): for line in bloc : text , styles = extract_style ( line , width = w , height = h ) yield Line ( page = p , bloc = b , x0 = line . x0 / w , x1 = line . x1 / w , y0 = 1 - line . y1 / h , y1 = 1 - line . y0 / h , page_width = w , page_height = h , text = text , styles = styles , ) remove_outside_lines ( lines , strict_mode = False ) Filter out lines that are outside the canvas. PARAMETER DESCRIPTION lines Dataframe of extracted lines TYPE: pd . DataFrame strict_mode Whether to remove the line if any part of it is outside the canvas, by default False TYPE: bool , optional DEFAULT: False RETURNS DESCRIPTION pd . DataFrame Filtered lines. Source code in edspdf/extractors/functional.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def remove_outside_lines ( lines : pd . DataFrame , strict_mode : bool = False , ) -> pd . DataFrame : \"\"\" Filter out lines that are outside the canvas. Parameters ---------- lines : pd.DataFrame Dataframe of extracted lines strict_mode : bool, optional Whether to remove the line if any part of it is outside the canvas, by default False Returns ------- pd.DataFrame Filtered lines. \"\"\" if strict_mode : lower = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) >= 0 upper = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) <= 1 lines = lines [ lower & upper ] else : below = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) < 0 above = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) > 0 lines = lines [ ~ ( below | above )] return lines","title":"functional"},{"location":"reference/extractors/functional/#edspdfextractorsfunctional","text":"","title":"edspdf.extractors.functional"},{"location":"reference/extractors/functional/#edspdf.extractors.functional.get_blocs","text":"Extract text blocs from a PDFMiner layout generator.","title":"get_blocs()"},{"location":"reference/extractors/functional/#edspdf.extractors.functional.get_blocs--arguments","text":"layout: PDFMiner layout generator. YIELDS DESCRIPTION bloc Text bloc TYPE: Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]] Source code in edspdf/extractors/functional.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_blocs ( layout : Iterator [ LTPage ], ) -> Iterator [ Tuple [ LTTextBoxHorizontal , int , float , float ]]: \"\"\" Extract text blocs from a PDFMiner layout generator. Arguments --------- layout: PDFMiner layout generator. Yields ------ bloc : Text bloc \"\"\" for i , page in enumerate ( layout ): width = page . width height = page . height for bloc in page : if isinstance ( bloc , LTTextBoxHorizontal ): yield bloc , i , width , height","title":"Arguments"},{"location":"reference/extractors/functional/#edspdf.extractors.functional.get_lines","text":"Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. PARAMETER DESCRIPTION layout PDFMiner layout object. TYPE: Iterator [ LTPage ] YIELDS DESCRIPTION Iterator [ Line ] Single line object. Source code in edspdf/extractors/functional.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_lines ( layout : Iterator [ LTPage ]) -> Iterator [ Line ]: \"\"\" Extract lines from a PDFMiner layout object. The line is reframed such that the origin is the top left corner. Parameters ---------- layout : Iterator[LTPage] PDFMiner layout object. Yields ------- Iterator[Line] Single line object. \"\"\" for b , ( bloc , p , w , h ) in enumerate ( get_blocs ( layout )): for line in bloc : text , styles = extract_style ( line , width = w , height = h ) yield Line ( page = p , bloc = b , x0 = line . x0 / w , x1 = line . x1 / w , y0 = 1 - line . y1 / h , y1 = 1 - line . y0 / h , page_width = w , page_height = h , text = text , styles = styles , )","title":"get_lines()"},{"location":"reference/extractors/functional/#edspdf.extractors.functional.remove_outside_lines","text":"Filter out lines that are outside the canvas. PARAMETER DESCRIPTION lines Dataframe of extracted lines TYPE: pd . DataFrame strict_mode Whether to remove the line if any part of it is outside the canvas, by default False TYPE: bool , optional DEFAULT: False RETURNS DESCRIPTION pd . DataFrame Filtered lines. Source code in edspdf/extractors/functional.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def remove_outside_lines ( lines : pd . DataFrame , strict_mode : bool = False , ) -> pd . DataFrame : \"\"\" Filter out lines that are outside the canvas. Parameters ---------- lines : pd.DataFrame Dataframe of extracted lines strict_mode : bool, optional Whether to remove the line if any part of it is outside the canvas, by default False Returns ------- pd.DataFrame Filtered lines. \"\"\" if strict_mode : lower = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) >= 0 upper = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) <= 1 lines = lines [ lower & upper ] else : below = lines [[ \"x1\" , \"y1\" ]] . max ( axis = 1 ) < 0 above = lines [[ \"x0\" , \"y0\" ]] . min ( axis = 1 ) > 0 lines = lines [ ~ ( below | above )] return lines","title":"remove_outside_lines()"},{"location":"reference/extractors/models/","text":"edspdf.extractors.models","title":"models"},{"location":"reference/extractors/models/#edspdfextractorsmodels","text":"","title":"edspdf.extractors.models"},{"location":"reference/extractors/pdfminer/","text":"edspdf.extractors.pdfminer PdfMinerExtractor Bases: BaseExtractor Extractor object. Given a PDF byte stream, produces a list of blocs. PARAMETER DESCRIPTION line_overlap See PDFMiner documentation TYPE: float DEFAULT: 0.5 char_margin See PDFMiner documentation TYPE: float DEFAULT: 2.0 line_margin See PDFMiner documentation TYPE: float DEFAULT: 0.5 word_margin See PDFMiner documentation TYPE: float DEFAULT: 0.1 boxes_flow See PDFMiner documentation TYPE: Optional [ float ] DEFAULT: 0.5 detect_vertical See PDFMiner documentation TYPE: bool DEFAULT: False all_texts See PDFMiner documentation TYPE: bool DEFAULT: False Source code in edspdf/extractors/pdfminer.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @registry . extractors . register ( \"pdfminer.v1\" ) class PdfMinerExtractor ( BaseExtractor ): \"\"\" Extractor object. Given a PDF byte stream, produces a list of blocs. Parameters ---------- line_overlap : float See PDFMiner documentation char_margin : float See PDFMiner documentation line_margin : float See PDFMiner documentation word_margin : float See PDFMiner documentation boxes_flow : Optional[float] See PDFMiner documentation detect_vertical : bool See PDFMiner documentation all_texts : bool See PDFMiner documentation \"\"\" def __init__ ( self , line_overlap : float = 0.5 , char_margin : float = 2.0 , line_margin : float = 0.5 , word_margin : float = 0.1 , boxes_flow : Optional [ float ] = 0.5 , detect_vertical : bool = False , all_texts : bool = False , ): self . laparams = LAParams ( line_overlap = line_overlap , char_margin = char_margin , line_margin = line_margin , word_margin = word_margin , boxes_flow = boxes_flow , detect_vertical = detect_vertical , all_texts = all_texts , ) def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines generate_lines ( pdf ) Generates dataframe from all blocs in the PDF. Arguments pdf: Byte stream representing the PDF. RETURNS DESCRIPTION pd . DataFrame DataFrame representing the blocs. Source code in edspdf/extractors/pdfminer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df extract ( pdf ) Process a single PDF document. PARAMETER DESCRIPTION pdf Raw byte representation of the PDF document. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame DataFrame containing one row for each line extracted using PDFMiner. Source code in edspdf/extractors/pdfminer.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines","title":"pdfminer"},{"location":"reference/extractors/pdfminer/#edspdfextractorspdfminer","text":"","title":"edspdf.extractors.pdfminer"},{"location":"reference/extractors/pdfminer/#edspdf.extractors.pdfminer.PdfMinerExtractor","text":"Bases: BaseExtractor Extractor object. Given a PDF byte stream, produces a list of blocs. PARAMETER DESCRIPTION line_overlap See PDFMiner documentation TYPE: float DEFAULT: 0.5 char_margin See PDFMiner documentation TYPE: float DEFAULT: 2.0 line_margin See PDFMiner documentation TYPE: float DEFAULT: 0.5 word_margin See PDFMiner documentation TYPE: float DEFAULT: 0.1 boxes_flow See PDFMiner documentation TYPE: Optional [ float ] DEFAULT: 0.5 detect_vertical See PDFMiner documentation TYPE: bool DEFAULT: False all_texts See PDFMiner documentation TYPE: bool DEFAULT: False Source code in edspdf/extractors/pdfminer.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @registry . extractors . register ( \"pdfminer.v1\" ) class PdfMinerExtractor ( BaseExtractor ): \"\"\" Extractor object. Given a PDF byte stream, produces a list of blocs. Parameters ---------- line_overlap : float See PDFMiner documentation char_margin : float See PDFMiner documentation line_margin : float See PDFMiner documentation word_margin : float See PDFMiner documentation boxes_flow : Optional[float] See PDFMiner documentation detect_vertical : bool See PDFMiner documentation all_texts : bool See PDFMiner documentation \"\"\" def __init__ ( self , line_overlap : float = 0.5 , char_margin : float = 2.0 , line_margin : float = 0.5 , word_margin : float = 0.1 , boxes_flow : Optional [ float ] = 0.5 , detect_vertical : bool = False , all_texts : bool = False , ): self . laparams = LAParams ( line_overlap = line_overlap , char_margin = char_margin , line_margin = line_margin , word_margin = word_margin , boxes_flow = boxes_flow , detect_vertical = detect_vertical , all_texts = all_texts , ) def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines","title":"PdfMinerExtractor"},{"location":"reference/extractors/pdfminer/#edspdf.extractors.pdfminer.PdfMinerExtractor.generate_lines","text":"Generates dataframe from all blocs in the PDF.","title":"generate_lines()"},{"location":"reference/extractors/pdfminer/#edspdf.extractors.pdfminer.PdfMinerExtractor.generate_lines--arguments","text":"pdf: Byte stream representing the PDF. RETURNS DESCRIPTION pd . DataFrame DataFrame representing the blocs. Source code in edspdf/extractors/pdfminer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def generate_lines ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Generates dataframe from all blocs in the PDF. Arguments --------- pdf: Byte stream representing the PDF. Returns ------- pd.DataFrame : DataFrame representing the blocs. \"\"\" pdf_stream = BytesIO ( pdf ) layout = extract_pages ( pdf_stream , laparams = self . laparams ) lines = list ( get_lines ( layout )) if not lines : return pd . DataFrame ( columns = [ \"page\" , \"bloc\" , \"x0\" , \"x1\" , \"y0\" , \"y1\" , \"page_width\" , \"page_height\" , \"text\" , \"styles\" , ] ) df = pd . DataFrame . from_records ([ line . dict () for line in lines ]) df [ \"line_id\" ] = range ( len ( df )) return df","title":"Arguments"},{"location":"reference/extractors/pdfminer/#edspdf.extractors.pdfminer.PdfMinerExtractor.extract","text":"Process a single PDF document. PARAMETER DESCRIPTION pdf Raw byte representation of the PDF document. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame DataFrame containing one row for each line extracted using PDFMiner. Source code in edspdf/extractors/pdfminer.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def extract ( self , pdf : bytes ) -> pd . DataFrame : \"\"\" Process a single PDF document. Parameters ---------- pdf : bytes Raw byte representation of the PDF document. Returns ------- pd.DataFrame DataFrame containing one row for each line extracted using PDFMiner. \"\"\" lines = self . generate_lines ( pdf ) # Remove empty lines lines = lines [ lines . text . str . len () > 0 ] # Remove lines that are outside the page lines = remove_outside_lines ( lines , strict_mode = True ) return lines","title":"extract()"},{"location":"reference/extractors/style/","text":"edspdf.extractors.style models BaseStyle Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float Style Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st from_fontname ( fontname , size , upright , x0 , x1 , y0 , y1 ) classmethod Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s __eq__ ( other ) Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o StyledText Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"`edspdf.extractors.style`"},{"location":"reference/extractors/style/#edspdfextractorsstyle","text":"","title":"edspdf.extractors.style"},{"location":"reference/extractors/style/#edspdf.extractors.style.models","text":"","title":"models"},{"location":"reference/extractors/style/#edspdf.extractors.style.models.BaseStyle","text":"Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float","title":"BaseStyle"},{"location":"reference/extractors/style/#edspdf.extractors.style.models.Style","text":"Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st","title":"Style"},{"location":"reference/extractors/style/#edspdf.extractors.style.models.Style.from_fontname","text":"Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s","title":"from_fontname()"},{"location":"reference/extractors/style/#edspdf.extractors.style.models.Style.__eq__","text":"Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o","title":"__eq__()"},{"location":"reference/extractors/style/#edspdf.extractors.style.models.StyledText","text":"Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"StyledText"},{"location":"reference/extractors/style/models/","text":"edspdf.extractors.style.models BaseStyle Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float Style Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st from_fontname ( fontname , size , upright , x0 , x1 , y0 , y1 ) classmethod Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s __eq__ ( other ) Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o StyledText Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"models"},{"location":"reference/extractors/style/models/#edspdfextractorsstylemodels","text":"","title":"edspdf.extractors.style.models"},{"location":"reference/extractors/style/models/#edspdf.extractors.style.models.BaseStyle","text":"Bases: BaseModel Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class BaseStyle ( BaseModel ): \"\"\" Model acting as an abstraction for a style. \"\"\" fontname : Optional [ str ] = None font : str style : str size : float upright : bool x0 : float x1 : float y0 : float y1 : float","title":"BaseStyle"},{"location":"reference/extractors/style/models/#edspdf.extractors.style.models.Style","text":"Bases: BaseStyle Model acting as an abstraction for a style. Source code in edspdf/extractors/style/models.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Style ( BaseStyle ): \"\"\" Model acting as an abstraction for a style. \"\"\" @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return cls . from_fontname ( fontname = char . fontname , size = char . size , upright = char . upright , x0 = char . x0 / width , x1 = char . x1 / width , y0 = 1 - char . y1 / height , y1 = 1 - char . y0 / height , ) def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o def __add__ ( self , other : \"Style\" ) -> \"Style\" : if self != other : raise ValueError ( \"You cannot add two different styles\" ) st = self . copy () st . x0 = min ( self . x0 , other . x0 ) st . x1 = max ( self . x1 , other . x1 ) st . y0 = min ( self . y0 , other . y0 ) st . y1 = max ( self . y1 , other . y1 ) return st","title":"Style"},{"location":"reference/extractors/style/models/#edspdf.extractors.style.models.Style.from_fontname","text":"Constructor using the compound fontname representation. PARAMETER DESCRIPTION fontname Compound description of the font. Often Arial , Arial,Bold or Arial-Bold TYPE: str size Character size. TYPE: float upright Whether the character is upright. TYPE: bool RETURNS DESCRIPTION Style Style representation. Source code in edspdf/extractors/style/models.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @classmethod def from_fontname ( cls , fontname : str , size : float , upright : bool , x0 : float , x1 : float , y0 : float , y1 : float , ) -> \"Style\" : \"\"\" Constructor using the compound `fontname` representation. Parameters ---------- fontname : str Compound description of the font. Often `Arial`, `Arial,Bold` or `Arial-Bold` size : float Character size. upright : bool Whether the character is upright. Returns ------- Style Style representation. \"\"\" # Round the size to avoid floating point aberrations. size = round ( size , 2 ) s = SEP_PATTERN . split ( fontname ) font = s . pop ( 0 ) if s : style = s [ - 1 ] else : style = \"Normal\" s = Style ( fontname = fontname , font = font , style = style , size = size , upright = upright , x0 = x0 , x1 = x1 , y0 = y0 , y1 = y1 , ) return s","title":"from_fontname()"},{"location":"reference/extractors/style/models/#edspdf.extractors.style.models.Style.__eq__","text":"Computes equality between two styles. PARAMETER DESCRIPTION other Style object to compare. TYPE: Style RETURNS DESCRIPTION bool Whether the two styles are equal. Source code in edspdf/extractors/style/models.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def __eq__ ( self , other : \"Style\" ) -> bool : \"\"\" Computes equality between two styles. Parameters ---------- other : Style Style object to compare. Returns ------- bool Whether the two styles are equal. \"\"\" s = ( self . font , self . style , round ( self . size , 2 ), self . upright ) o = ( other . font , other . style , round ( other . size , 2 ), other . upright ) return s == o","title":"__eq__()"},{"location":"reference/extractors/style/models/#edspdf.extractors.style.models.StyledText","text":"Bases: BaseModel Abstraction of a word, containing the style and the text. Source code in edspdf/extractors/style/models.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class StyledText ( BaseModel ): \"\"\" Abstraction of a word, containing the style and the text. \"\"\" text : str style : Style @classmethod def from_char ( cls , char : LTChar , width : float , height : float , ): return StyledText ( text = SPACE_PATTERN . sub ( \" \" , char . _text ), style = Style . from_char ( char , width = width , height = height ), ) def add_space ( self ) -> None : self . text = f \" { self . text . rstrip () } \" def rstrip ( self ) -> None : self . text = self . text . rstrip () def __add__ ( self , other : \"StyledText\" ) -> \"StyledText\" : st = StyledText ( text = self . text + other . text , style = self . style + other . style , ) return st def __iadd__ ( self , other : \"StyledText\" ) -> \"StyledText\" : return self + other","title":"StyledText"},{"location":"reference/extractors/style/style/","text":"edspdf.extractors.style.style","title":"style"},{"location":"reference/extractors/style/style/#edspdfextractorsstylestyle","text":"","title":"edspdf.extractors.style.style"},{"location":"reference/misc/","text":"edspdf.misc","title":"`edspdf.misc`"},{"location":"reference/misc/#edspdfmisc","text":"","title":"edspdf.misc"},{"location":"reference/misc/package/","text":"edspdf.misc.package","title":"package"},{"location":"reference/misc/package/#edspdfmiscpackage","text":"","title":"edspdf.misc.package"},{"location":"reference/readers/","text":"edspdf.readers reader PdfReader Source code in edspdf/readers/reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @registry . readers . register ( \"pdf-reader.v1\" ) class PdfReader : def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines def prepare_and_predict ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : lines = self . prepare_data ( pdf , ** context ) lines = self . predict ( lines ) return lines def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result __init__ ( extractor = None , classifier = None , aggregator = None , transform = None , meta_labels = dict ()) Reads a text-based PDF document, PARAMETER DESCRIPTION extractor Text bloc extractor. TYPE: BaseExtractor DEFAULT: None classifier Classifier model, to assign a section (eg body , header , etc). TYPE: BaseClassifier DEFAULT: None aggregator Aggregator model, to compile labelled text blocs together. TYPE: BaseAggregator DEFAULT: None transform Transformation to apply before classification. TYPE: BaseTransform , optional DEFAULT: None meta_labels Dictionary of hierarchical labels (eg table is probably within the body ). TYPE: Dict [ str , str ], optional DEFAULT: dict() Source code in edspdf/readers/reader.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels predict ( lines ) Predict the label of each text bloc. PARAMETER DESCRIPTION lines Text blocs to label. TYPE: pd . DataFrame RETURNS DESCRIPTION pd . DataFrame Labelled text blocs. Source code in edspdf/readers/reader.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines prepare_data ( pdf , ** context ) Prepare data before classification. Can also be used to generate the training dataset for the classifier. PARAMETER DESCRIPTION pdf PDF document, as bytes. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame Text blocs as a pandas DataFrame. Source code in edspdf/readers/reader.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines __call__ ( pdf , ** context ) Process the PDF document. PARAMETER DESCRIPTION pdf Byte representation of the PDF document. TYPE: bytes context : Any Any contextual information that is used by the classifier (eg document type or source). RETURNS DESCRIPTION Dict [ str , str ] Dictionary containing the aggregated text. Source code in edspdf/readers/reader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"`edspdf.readers`"},{"location":"reference/readers/#edspdfreaders","text":"","title":"edspdf.readers"},{"location":"reference/readers/#edspdf.readers.reader","text":"","title":"reader"},{"location":"reference/readers/#edspdf.readers.reader.PdfReader","text":"Source code in edspdf/readers/reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @registry . readers . register ( \"pdf-reader.v1\" ) class PdfReader : def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines def prepare_and_predict ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : lines = self . prepare_data ( pdf , ** context ) lines = self . predict ( lines ) return lines def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"PdfReader"},{"location":"reference/readers/#edspdf.readers.reader.PdfReader.__init__","text":"Reads a text-based PDF document, PARAMETER DESCRIPTION extractor Text bloc extractor. TYPE: BaseExtractor DEFAULT: None classifier Classifier model, to assign a section (eg body , header , etc). TYPE: BaseClassifier DEFAULT: None aggregator Aggregator model, to compile labelled text blocs together. TYPE: BaseAggregator DEFAULT: None transform Transformation to apply before classification. TYPE: BaseTransform , optional DEFAULT: None meta_labels Dictionary of hierarchical labels (eg table is probably within the body ). TYPE: Dict [ str , str ], optional DEFAULT: dict() Source code in edspdf/readers/reader.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels","title":"__init__()"},{"location":"reference/readers/#edspdf.readers.reader.PdfReader.predict","text":"Predict the label of each text bloc. PARAMETER DESCRIPTION lines Text blocs to label. TYPE: pd . DataFrame RETURNS DESCRIPTION pd . DataFrame Labelled text blocs. Source code in edspdf/readers/reader.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines","title":"predict()"},{"location":"reference/readers/#edspdf.readers.reader.PdfReader.prepare_data","text":"Prepare data before classification. Can also be used to generate the training dataset for the classifier. PARAMETER DESCRIPTION pdf PDF document, as bytes. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame Text blocs as a pandas DataFrame. Source code in edspdf/readers/reader.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines","title":"prepare_data()"},{"location":"reference/readers/#edspdf.readers.reader.PdfReader.__call__","text":"Process the PDF document. PARAMETER DESCRIPTION pdf Byte representation of the PDF document. TYPE: bytes context : Any Any contextual information that is used by the classifier (eg document type or source). RETURNS DESCRIPTION Dict [ str , str ] Dictionary containing the aggregated text. Source code in edspdf/readers/reader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"__call__()"},{"location":"reference/readers/reader/","text":"edspdf.readers.reader PdfReader Source code in edspdf/readers/reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @registry . readers . register ( \"pdf-reader.v1\" ) class PdfReader : def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines def prepare_and_predict ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : lines = self . prepare_data ( pdf , ** context ) lines = self . predict ( lines ) return lines def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result __init__ ( extractor = None , classifier = None , aggregator = None , transform = None , meta_labels = dict ()) Reads a text-based PDF document, PARAMETER DESCRIPTION extractor Text bloc extractor. TYPE: BaseExtractor DEFAULT: None classifier Classifier model, to assign a section (eg body , header , etc). TYPE: BaseClassifier DEFAULT: None aggregator Aggregator model, to compile labelled text blocs together. TYPE: BaseAggregator DEFAULT: None transform Transformation to apply before classification. TYPE: BaseTransform , optional DEFAULT: None meta_labels Dictionary of hierarchical labels (eg table is probably within the body ). TYPE: Dict [ str , str ], optional DEFAULT: dict() Source code in edspdf/readers/reader.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels predict ( lines ) Predict the label of each text bloc. PARAMETER DESCRIPTION lines Text blocs to label. TYPE: pd . DataFrame RETURNS DESCRIPTION pd . DataFrame Labelled text blocs. Source code in edspdf/readers/reader.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines prepare_data ( pdf , ** context ) Prepare data before classification. Can also be used to generate the training dataset for the classifier. PARAMETER DESCRIPTION pdf PDF document, as bytes. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame Text blocs as a pandas DataFrame. Source code in edspdf/readers/reader.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines __call__ ( pdf , ** context ) Process the PDF document. PARAMETER DESCRIPTION pdf Byte representation of the PDF document. TYPE: bytes context : Any Any contextual information that is used by the classifier (eg document type or source). RETURNS DESCRIPTION Dict [ str , str ] Dictionary containing the aggregated text. Source code in edspdf/readers/reader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"reader"},{"location":"reference/readers/reader/#edspdfreadersreader","text":"","title":"edspdf.readers.reader"},{"location":"reference/readers/reader/#edspdf.readers.reader.PdfReader","text":"Source code in edspdf/readers/reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 @registry . readers . register ( \"pdf-reader.v1\" ) class PdfReader : def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines def prepare_and_predict ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : lines = self . prepare_data ( pdf , ** context ) lines = self . predict ( lines ) return lines def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"PdfReader"},{"location":"reference/readers/reader/#edspdf.readers.reader.PdfReader.__init__","text":"Reads a text-based PDF document, PARAMETER DESCRIPTION extractor Text bloc extractor. TYPE: BaseExtractor DEFAULT: None classifier Classifier model, to assign a section (eg body , header , etc). TYPE: BaseClassifier DEFAULT: None aggregator Aggregator model, to compile labelled text blocs together. TYPE: BaseAggregator DEFAULT: None transform Transformation to apply before classification. TYPE: BaseTransform , optional DEFAULT: None meta_labels Dictionary of hierarchical labels (eg table is probably within the body ). TYPE: Dict [ str , str ], optional DEFAULT: dict() Source code in edspdf/readers/reader.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , extractor : Optional [ BaseExtractor ] = None , classifier : Optional [ BaseClassifier ] = None , aggregator : Optional [ BaseAggregator ] = None , transform : Optional [ BaseTransform ] = None , meta_labels : Dict [ str , str ] = dict (), ) -> None : \"\"\" Reads a text-based PDF document, Parameters ---------- extractor : BaseExtractor Text bloc extractor. classifier : BaseClassifier Classifier model, to assign a section (eg `body`, `header`, etc). aggregator : BaseAggregator Aggregator model, to compile labelled text blocs together. transform : BaseTransform, optional Transformation to apply before classification. meta_labels : Dict[str, str], optional Dictionary of hierarchical labels (eg `table` is probably within the `body`). \"\"\" self . extractor = extractor self . classifier = classifier self . aggregator = aggregator self . transform = transform self . meta_labels = meta_labels","title":"__init__()"},{"location":"reference/readers/reader/#edspdf.readers.reader.PdfReader.predict","text":"Predict the label of each text bloc. PARAMETER DESCRIPTION lines Text blocs to label. TYPE: pd . DataFrame RETURNS DESCRIPTION pd . DataFrame Labelled text blocs. Source code in edspdf/readers/reader.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def predict ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Predict the label of each text bloc. Parameters ---------- lines : pd.DataFrame Text blocs to label. Returns ------- pd.DataFrame Labelled text blocs. \"\"\" lines [ \"label\" ] = self . classifier . predict ( lines ) lines [ \"meta_label\" ] = lines . label . replace ( self . meta_labels ) return lines","title":"predict()"},{"location":"reference/readers/reader/#edspdf.readers.reader.PdfReader.prepare_data","text":"Prepare data before classification. Can also be used to generate the training dataset for the classifier. PARAMETER DESCRIPTION pdf PDF document, as bytes. TYPE: bytes RETURNS DESCRIPTION pd . DataFrame Text blocs as a pandas DataFrame. Source code in edspdf/readers/reader.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def prepare_data ( self , pdf : bytes , ** context : Any ) -> pd . DataFrame : \"\"\" Prepare data before classification. Can also be used to generate the training dataset for the classifier. Parameters ---------- pdf : bytes PDF document, as bytes. Returns ------- pd.DataFrame Text blocs as a pandas DataFrame. \"\"\" lines = self . extractor ( pdf ) for key , value in context . items (): lines [ key ] = value # Apply transformation if self . transform is not None : lines = self . transform ( lines ) return lines","title":"prepare_data()"},{"location":"reference/readers/reader/#edspdf.readers.reader.PdfReader.__call__","text":"Process the PDF document. PARAMETER DESCRIPTION pdf Byte representation of the PDF document. TYPE: bytes context : Any Any contextual information that is used by the classifier (eg document type or source). RETURNS DESCRIPTION Dict [ str , str ] Dictionary containing the aggregated text. Source code in edspdf/readers/reader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __call__ ( self , pdf : bytes , ** context : Any ) -> Union [ Dict [ str , str ], Tuple [ Dict [ str , str ], Dict [ str , Any ]]]: \"\"\" Process the PDF document. Parameters ---------- pdf : bytes Byte representation of the PDF document. context : Any Any contextual information that is used by the classifier (eg document type or source). Returns ------- Dict[str, str] Dictionary containing the aggregated text. \"\"\" lines = self . prepare_and_predict ( pdf , ** context ) result = self . aggregator ( lines ) return result","title":"__call__()"},{"location":"reference/transforms/","text":"edspdf.transforms base BaseTransform Bases: ABC Source code in edspdf/transforms/base.py 6 7 8 9 10 11 12 13 14 class BaseTransform ( ABC ): @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> pd . DataFrame : return self . transform ( lines ) transform ( lines ) abstractmethod Handles the transformation Source code in edspdf/transforms/base.py 7 8 9 10 11 @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\"","title":"`edspdf.transforms`"},{"location":"reference/transforms/#edspdftransforms","text":"","title":"edspdf.transforms"},{"location":"reference/transforms/#edspdf.transforms.base","text":"","title":"base"},{"location":"reference/transforms/#edspdf.transforms.base.BaseTransform","text":"Bases: ABC Source code in edspdf/transforms/base.py 6 7 8 9 10 11 12 13 14 class BaseTransform ( ABC ): @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> pd . DataFrame : return self . transform ( lines )","title":"BaseTransform"},{"location":"reference/transforms/#edspdf.transforms.base.BaseTransform.transform","text":"Handles the transformation Source code in edspdf/transforms/base.py 7 8 9 10 11 @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\"","title":"transform()"},{"location":"reference/transforms/base/","text":"edspdf.transforms.base BaseTransform Bases: ABC Source code in edspdf/transforms/base.py 6 7 8 9 10 11 12 13 14 class BaseTransform ( ABC ): @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> pd . DataFrame : return self . transform ( lines ) transform ( lines ) abstractmethod Handles the transformation Source code in edspdf/transforms/base.py 7 8 9 10 11 @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\"","title":"base"},{"location":"reference/transforms/base/#edspdftransformsbase","text":"","title":"edspdf.transforms.base"},{"location":"reference/transforms/base/#edspdf.transforms.base.BaseTransform","text":"Bases: ABC Source code in edspdf/transforms/base.py 6 7 8 9 10 11 12 13 14 class BaseTransform ( ABC ): @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\" def __call__ ( self , lines : pd . DataFrame ) -> pd . DataFrame : return self . transform ( lines )","title":"BaseTransform"},{"location":"reference/transforms/base/#edspdf.transforms.base.BaseTransform.transform","text":"Handles the transformation Source code in edspdf/transforms/base.py 7 8 9 10 11 @abstractmethod def transform ( self , lines : pd . DataFrame ) -> pd . DataFrame : \"\"\" Handles the transformation \"\"\"","title":"transform()"},{"location":"reference/transforms/transforms/","text":"edspdf.transforms.transforms","title":"transforms"},{"location":"reference/transforms/transforms/#edspdftransformstransforms","text":"","title":"edspdf.transforms.transforms"},{"location":"reference/visualization/","text":"edspdf.visualization","title":"`edspdf.visualization`"},{"location":"reference/visualization/#edspdfvisualization","text":"","title":"edspdf.visualization"},{"location":"reference/visualization/annotations/","text":"edspdf.visualization.annotations","title":"annotations"},{"location":"reference/visualization/annotations/#edspdfvisualizationannotations","text":"","title":"edspdf.visualization.annotations"},{"location":"reference/visualization/merge/","text":"edspdf.visualization.merge","title":"merge"},{"location":"reference/visualization/merge/#edspdfvisualizationmerge","text":"","title":"edspdf.visualization.merge"},{"location":"utilities/","text":"Overview EDS-PDF provides a few utilities help annotate PDF documents, and debug the output of an extraction pipeline.","title":"Overview"},{"location":"utilities/#overview","text":"EDS-PDF provides a few utilities help annotate PDF documents, and debug the output of an extraction pipeline.","title":"Overview"},{"location":"utilities/alignment/","text":"Alignment To simplify the annotation process, EDS-PDF provides a utility that aligns bounding boxes with text blocs extracted from a PDF document. This is particularly useful for annotating documents. Blocs Blocs + Annotation Aligned Merged Blocs","title":"Alignment"},{"location":"utilities/alignment/#alignment","text":"To simplify the annotation process, EDS-PDF provides a utility that aligns bounding boxes with text blocs extracted from a PDF document. This is particularly useful for annotating documents. Blocs Blocs + Annotation Aligned Merged Blocs","title":"Alignment"},{"location":"utilities/visualisation/","text":"Visualisation EDS-PDF provides utilities to help you visualise the output of the pipeline. Visualising a pipeline's output You can use EDS-PDF to overlay labelled bounding boxes on top of a PDF document. import edspdf from pathlib import Path from edspdf.visualization.annotations import show_annotations config = \"\"\" [reader] @readers = \"pdf-reader.v1\" [reader.extractor] @extractors = \"pdfminer.v1\" [reader.classifier] @classifiers = \"mask.v1\" x0 = 0.1 x1 = 0.9 y0 = 0.4 y1 = 0.9 threshold = 0.1 [reader.aggregator] @aggregators = \"simple.v1\" \"\"\" reader = edspdf . from_str ( config ) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () # Construct the DataFrame of blocs lines = reader . prepare_and_predict ( pdf ) # Compute an image representation of each page of the PDF # overlaid with the predicted bounding boxes imgs = show_annotations ( pdf = pdf , annotations = lines ) imgs [ 0 ] If you run this code in a Jupyter notebook, you'll see the following: Merging blocs together To help debug a pipeline (or a labelled dataset), you might want to merge blocs together according to their labels. EDS-PDF provides a merge_lines method that does just that. # \u2191 Omitted code above \u2191 from edspdf.visualization.merge import merge_lines merged = merge_lines ( lines ) imgs = show_annotations ( pdf = pdf , annotations = merged ) imgs [ 0 ] See the difference: Original Merged The merge_lines method uses the notion of maximal cliques to compute merges. It forbids the combined blocs from overlapping with any bloc from another label.","title":"Visualisation"},{"location":"utilities/visualisation/#visualisation","text":"EDS-PDF provides utilities to help you visualise the output of the pipeline.","title":"Visualisation"},{"location":"utilities/visualisation/#visualising-a-pipelines-output","text":"You can use EDS-PDF to overlay labelled bounding boxes on top of a PDF document. import edspdf from pathlib import Path from edspdf.visualization.annotations import show_annotations config = \"\"\" [reader] @readers = \"pdf-reader.v1\" [reader.extractor] @extractors = \"pdfminer.v1\" [reader.classifier] @classifiers = \"mask.v1\" x0 = 0.1 x1 = 0.9 y0 = 0.4 y1 = 0.9 threshold = 0.1 [reader.aggregator] @aggregators = \"simple.v1\" \"\"\" reader = edspdf . from_str ( config ) # Get a PDF pdf = Path ( \"letter.pdf\" ) . read_bytes () # Construct the DataFrame of blocs lines = reader . prepare_and_predict ( pdf ) # Compute an image representation of each page of the PDF # overlaid with the predicted bounding boxes imgs = show_annotations ( pdf = pdf , annotations = lines ) imgs [ 0 ] If you run this code in a Jupyter notebook, you'll see the following:","title":"Visualising a pipeline's output"},{"location":"utilities/visualisation/#merging-blocs-together","text":"To help debug a pipeline (or a labelled dataset), you might want to merge blocs together according to their labels. EDS-PDF provides a merge_lines method that does just that. # \u2191 Omitted code above \u2191 from edspdf.visualization.merge import merge_lines merged = merge_lines ( lines ) imgs = show_annotations ( pdf = pdf , annotations = merged ) imgs [ 0 ] See the difference: Original Merged The merge_lines method uses the notion of maximal cliques to compute merges. It forbids the combined blocs from overlapping with any bloc from another label.","title":"Merging blocs together"}]}